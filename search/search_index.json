{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"GHGA User Documentation","text":"<p>Welcome to the GHGA User Documentation. On these pages you will find relevant information on services provided by GHGA - the German Human Genome-Phenome Archive. </p> <p>Limitations on External Submissions - November 2024</p> <p>GHGA has only recently launched the functionality of the GHGA Data Portal. Our ongoing efforts concentrate on improving the data upload processes and the overall user experience for external submissions. In general, data upload by external users is not yet possible as it includes manual steps. See also this section in our FAQ and the respective user story.</p>"},{"location":"#getting-started-user-stories","title":"Getting Started - User Stories","text":"<p>The GHGA Data Portal supports researchers in browsing, accessing, and submitting human omics data under controlled access. This section provides step-by-step guidance for different user stories.</p> <p></p> <ol> <li>Browsing Data \u2013 Search and filter available datasets to find relevant research data. Learn how to navigate the GHGA Data Portal efficiently.</li> <li>Accessing Data \u2013 Follow this step-by-step process to request dataset access, including login requirements and approval workflows.</li> <li>Submitting Data \u2013 Understand the submission process, including metadata preparation, file uploads, and necessary legal agreements.</li> <li>Data Use &amp; Access Guide \u2013 Learn about suggested ethical standards, decision-making criteria, and policies for handling access requests.</li> </ol>"},{"location":"#ghga-terms-of-use","title":"GHGA Terms of Use","text":"<p>The GHGA Terms of Use<sup>1</sup> define the services offered by the GHGA Consortium and the performance levels of those services that users can expect. They also define the conditions that apply to users when using GHGA.</p>"},{"location":"#contact","title":"Contact","text":"<p>Please reach out to the GHGA Helpdesk for any questions on GHGA.</p>"},{"location":"#about-ghga","title":"About GHGA","text":""},{"location":"#funding-and-legal-status","title":"Funding and Legal Status","text":"<p>The 6251a85a-47d0-11ee-be56-0242ac120002:e4620f7cd4dc59e517e295ef9a7c3996:&lt;__None__&gt; is not an independent legal entity but an association of research institutions from all over Germany. It is funded by the Deutsche Forschungsgemeinschaft (DFG, German Research Foundation) as part of  the National Research Data Infrastructure (NFDI). </p> <p>GHGA \u2013 The German Human Genome-Phenome Archive (www.ghga.de, Grant Number 441914366).</p>"},{"location":"#listing-in-fair-sharing-repositories","title":"Listing in FAIR-Sharing Repositories","text":"<p>GHGA is listed in the following repositories as a FAIR-sharing ressources:</p> <ul> <li>FAIRsharing.org - doi.org/10.25504/FAIRsharing.e2df6a </li> <li> <p>re3data.org - doi.org/10.17616/R31NJNQB</p> </li> </ul> <ol> <li> <p>The GHGA Consortium. (2024). Terms of Use GHGA Data Infrastructure (Version 1.1). Zenodo. 10.5281/zenodo.14357642 Most recent Version: 10.5281/zenodo.11146386 \u21a9</p> </li> </ol>"},{"location":"faq/","title":"Frequently Asked Questions - FAQ","text":"<p>Abstract</p> <p>This page is a collection of common questions on the GHGA Data Portal. If you have further questions, please reach out to the GHGA Helpdesk.</p>"},{"location":"faq/#what-are-the-functions-of-the-ghga-data-portal","title":"What are the functions of the GHGA Data Portal?","text":"<p>The GHGA Data Portal allows users to browse, search, and download omics datasets submitted to the GHGA. It uses the GHGA Metadata Model.</p>"},{"location":"faq/#what-data-can-be-found-on-ghga-data-portal","title":"What data can be found on GHGA Data Portal?","text":"<p>Please visit the GHGA Data Portal browse page and find your data of interest either by a keyword search or by using the selectors on the left side. Currently, we are only displaying datasets from GHGA partner institutions.</p>"},{"location":"faq/#how-to-upload-your-data-to-the-ghga-data-portal","title":"How to upload your data to the GHGA Data Portal?","text":"<p>Currently GHGA is still in an early phase of the project and is therefore in general only accepting data submissions from partner institutions. If you would like to submit human omics data to GHGA, please contact the GHGA Helpdesk. To stay informed on new feature releases and updates to GHGA, please sign up for our GHGA Newsletter. </p> <p>To find out more about how to prepare for a submission, please visit the respective user story.</p>"},{"location":"faq/#how-should-i-publicly-reference-my-data-deposition-in-ghga","title":"How should I publicly reference my data deposition in GHGA?","text":"<p>Data depositions should be referenced via the Study Accession (e.g. <code>GHGAS12079965883832</code>). To unify how data is referenced, please always use the recommended data availability statement.</p>"},{"location":"faq/#how-to-get-data-access","title":"How to get data access?","text":"<p>The GHGA Data Portal allows users to request access to data through the portal. Identify your dataset of interest using the browse and filter functions of the GHGA Data Portal. Click on the \"Request access\" button. This will direct you to a data access request form. Complete the form with the necessary information and submit it to request access to the dataset. The data access request will be sent to the 6251a85a-47d0-11ee-be56-0242ac120002:6da5b94f306c9adba3717fdd2a4b395b:, who will will review your request and respond accordingly. Please note that GHGA is not involved in the further process of negotiating the data access."},{"location":"faq/#where-can-i-find-my-life-science-id-ls-id","title":"Where can I find my Life Science ID (LS ID)?","text":"<p>In order to ensure that only authorised people can access our systems, GHGA utilises Life Science Login (LS Login) to authenticate users. The LS ID (e.g. <code>777xc437f725f58660456780tt01d5l999f9b123456@lifescience-ri.eu</code>) is displayed in the Life Science RI user profile and can also be accessed via the user account in the GHGA Data Portal.</p> LS ID User Profile Screenshot <p> Life Science RI user profile</p>"},{"location":"faq/#my-data-access-request-got-approved-but-i-cannot-download-the-data","title":"My data access request got approved but I cannot download the data?","text":"<p>The GHGA Data Portal requires authentication of a user via an 6251a85a-47d0-11ee-be56-0242ac120002:2f810c0a6ded1354a1bfe82a5269331c:, to ensure that the registered user is the person specified in the Data Transfer Agreement between 6251a85a-47d0-11ee-be56-0242ac120002:54b591223d49609cdf9740df31ab2065: and 6251a85a-47d0-11ee-be56-0242ac120002:bdb1333bb0658f0a026ec1cb89666c52:. For more information about this process, please visit the respective user story. Please note that the verification process is currently manually supervised by GHGA 6251a85a-47d0-11ee-be56-0242ac120002:5c9b0e93d95888e65836ac3076d757f7: and can take up to three working days."},{"location":"glossary/","title":"Glossary","text":"<p>Abstract</p> <p>This page collect common terms and acronyms used within the GHGA Project.</p> Administrative Data Data which are generated through the operation of GHGA Data Infrastructure. This may include personal data which is directly identifying, such as names and email addresses which are used to communicate with, and support, service users. It may also include personal data and business data which are used internally by staff working on behalf of GHGA Central or GHGA Data Hubs. Personal administrative data is jointly controlled by the GHGA Operations Consortium members according to the Joint Controller Contract. Central-to-Data-Hub-Bilateral Contract (Bilateral Contract) Agreement between GHGA Central and a GHGA Data Hub. Based on the GHGA Data Hub Cooperation Contract it regulates the relationship between GHGA Central and the Data Hub and the corresponding rights and responsibilities in full detail. In particular it defines the processor to sub-processor relationship between GHGA Central and the individual Data Hub. It also enables adjustments with respect to local infrastructures and federal data protection law where required. Data Access Committee (DAC) An abstract body, potentially a panel of people, deciding on Data Access Requests and authorised by the Research Data Controller.  Data Access Committee Representative (DACR) A natural person authorised by the Data Access Committee to communicate decisions made by the DAC to GHGA. Data Access Request (DAR) A request to obtain access to Research Data stated by a Data Requester. Data Availability Statement Proposed text how data included in GHGA should be referenced in publications, websites or other media. Details can be found here. Data Processing Contract (DPC) Bilateral agreement signed by GHGA Central and a Research Data Controller who wishes to deposit data in the archive. The agreement regulates the rights and duties of the controller and GHGA Central in processing the deposited data. Data Requester (DR) Institution that requests access to data via the GHGA Data Infrastructure. Data Requester Representative (DRR) Natural person acting on behalf of the Data Requester. The term is used for persons communicating data access requests to the Research Data Controller on behalf of the Data Requester as well as for persons that were authorised to retrieve the data for the Data Requester in the corresponding Data Transfer Agreement. Data Steward Data Stewards are the staff members who (besides other duties) operate the GHGA Helpdesk. They are responsible for assisting users of the GHGA Data Infrastructure with data transfer to the GHGA Data Infrastructure, access requests and responding to queries. Data Stewards will be employed at each of the GHGA Data Hubs. Data Submitters Users who are depositing data with GHGA Central (and includes the Data Controller, if not the same person(s), as defined in the Data Processing Contract). The Data Controllers will regularly operate one or several Data Access Committees (DACs) facilitating decision-making regarding access to the research data shared via the GHGA Data Infrastructure. Data Transfer Agreement (DTA) An agreement signed between a Research Data Controller and a Data Requester before a Data Access Request is approved. GHGA is not involved in the contractual relationship here, but is informed by the Research Data Controller once an appropriate agreement is in place. Please note: Depending on the institutions, this is sometimes also referred to as a Data Access Agreement (DAA) or Data Use Agreement (DUA).  European Genome-phenome Archive (EGA) The European Genome-Phenome Archive (EGA) provides archiving and sharing support for personally identifiable genetic and phenotypic data. It is operated jointly by the European Molecular Biology Laboratory - European Bioinformatics Institute (EMBL-EBI), an intergovernmental organisation, and the Centre for Genomic Regulation in Barcelona (CRG). The EGA is developing a federated model through which national nodes will take on the archiving of genomic-phenomic data for their country; this federated network of institutions will be referred to as the federated EGA (fEGA). EGA will take over the coordinating function as operator of EGA-Central, GHGA is planned as the national node for Germany. Federated EGA Collaboration Agreement Agreement between GHGA Central and EGA Central. Defines the rights and responsibilities of EGA Central and GHGA as the German Node. Describes the governance structure of the Federated EGA network. Includes details around IP, liability, disputes, and off-boarding. No personal Research Data is exchanged between GHGA Central and EGA Central (see \u00a72.4.2). GHGA Central Deutsches Krebsforschungszentrum (DKFZ) shall be the legal entity responsible for GHGA Data Infrastructure. The responsibilities are outlined in the GHGA Data Hub Cooperation Contract and are to be fulfilled in accordance with the regulations outlined in this contract. These responsibilities will include taking on the role of a data processor for the research data submitted to the GHGA Data Infrastructure. Within this agreement, DKFZ will be referred to as GHGA Central. DKFZ will also operate a GHGA Data Hub. GHGA Collaboration Contract Regulates the organisation of the GHGA Consortium to carry out the GHGA Project. Does not regulate the exchange of Person-related Data. GHGA Consortium The organisations that have signed the GHGA Cooperation Contract (Appendix 1 to the GHGA Data Hub Cooperation Agreement) in December 2020 and receive (some of) their funding as part of the Nationale Forschungsdateninfrastruktur (NFDI) from the German Research Foundation (DFG). GHGA Data Hub Cooperation Contract (DHCC) This contract is agreed by GHGA Central and GHGA Operations Consortium members that operate, or wish to operate, a GHGA Data Hub. The contract sets out the structure of the Operations Consortium, including a definition of the roles and responsibilities of members as well as the data governance framework. The appendices define a number of common standards that will be utilised by GHGA, including the Joint Controller Agreement for Personal Administrative Data. GHGA Data Hub Pre-Operations Consortium Board This board is responsible for the initial development of the GHGA Operations Consortium. This may include members from any GHGA Member institution. GHGA Data Hub A GHGA Consortium Member that stores and processes research data for the purposes of archiving and secondary analysis for scientific research purposes on behalf of GHGA Central. The responsibilities are set out in the GHGA Data Hub Cooperation Contract. GHGA Data Infrastructure GHGA Central, together with the GHGA Operations Consortium, will operate an IT infrastructure to enable FAIR (findable, accessible, interoperable and reusable) data sharing of human omics data for scientific research purposes as defined by the Joint Controller Contract ((Appendix 3 to the GHGA Data Hub Cooperation Agreement)) and the Bilateral Contracts. GHGA Helpdesk The GHGA Helpdesk is the main point of contact for service users. To open a ticket send a mail to helpdesk@ghga.de The helpdesk software is operated by the DKFZ as GHGA Central and is also available via helpdesk.ghga.de GHGA Operations Consortium Board The GHGA Operations Consortium Board shall meet bimonthly to take decisions regarding the operation of the GHGA Operations Consortium and GHGA Data Infrastructure. It will also provide advice and guidance to GHGA Central on data processing matters. GHGA Operations Consortium GHGA Central and the GHGA Data Hub s. The GHGA Operations Consortium Board will be responsible for decision-making within the GHGA Operations Consortium. GHGA Operations Data Committee The GHGA Operations Data Committee will be made up of the Data Stewards from each of the GHGA Data Hubs guided by a Helpdesk Lead. This committee shall meet weekly to discuss the allocation of research data to GHGA Data Hubs and other matters relating to the operation of the GHGA Data Infrastructure. The Helpdesk Lead will report the outcomes of the meetings with the GHGA Operations Consortium Board. GHGA Partner An organisation that is working or intends to work with the GHGA Consortium but which does not receive funding as part of the NFDI-DFG funding. The nature of the relationship will be defined in a Partner Agreement but they will not process research data on behalf of GHGA Central and do not become involved in the processing of personal administrative data. GHGA Project The Project refers to the overall GHGA structure. This includes GHGA Central, the GHGA Consortium, and GHGA Partners who are working together to make genomic-phenomic data available. GHGA Request for Comments (GRFC) GHGA Request for Comments is a short document type developed to clarify technical, legal and organisational assumptions that set the boundaries for the implementation of services and solutions that GHGA offers. Helpdesk Lead The Helpdesk Lead manages the tasks of the GHGA Helpdesk and coordinates the work of the Data Stewards. The Helpdesk Lead is responsible for responding to requests from data subjects regarding administrative data and acts as a liaison between the Data Stewards and the GHGA Operations Consortium Board. Independent Verification Address (IVA) The independent verification address (IVA) is used to add additional security towards the identification of users in the GHGA Data Portal. An IVA is a verification factor that is independent of the primary route of authentication in the GHGA Data Portal using 6251a85a-47d0-11ee-be56-0242ac120002:662f28c7e0ecc27b3c46a70e89e547ba:&lt;__None__&gt;. IVAs can be phone numbers or postal addresses to which GHGA will send a code that then needs to be entered back into the GHGA Data Portal by the user. The user's account is then verified for this particular address. Institutional Review Board (IRB) See 6251a85a-47d0-11ee-be56-0242ac120002:379fdbc4431591b7f2ec4a16d8db205a:&lt;__None__&gt;. Joint Controller Agreement for Personal Administrative Data (JCA) The document governs the joint controllership of the 6251a85a-47d0-11ee-be56-0242ac120002:3c9591d5a1220ea3125d6073cbefa81b:&lt;__None__&gt; by the institutions which are part of the GHGA Operations Consortium. Appendix to GHGA Data Hub Cooperation Contract. LS ID For the usage of the services of the GHGA Data Portal, a Life Science Login / LS ID is necessary. Life Science Login is an authentication service from EOSC-Life, for details see lifescience-ri.eu/ls-login/. For identification purposes, an LS ID is needed, see further details here. Metadata Processing Contract This agreement covers the deposition and sharing of metadata in the GHGA Metadata Catalog during the GHGA Catalog phase of the project. During GHGA Catalog, only Non-personal Metadata describing Research Data will be processed and shared; the corresponding Research Data and Personal Metadata remain with the Data Controller and are not stored by the GHGA Operations Consortium. Metadata Information that describes or annotates research data to aid understanding or to describe the relationship between data items. It may be personal or non-personal. Non-personal Metadata Information that describes or annotates research data to facilitate its interpretation or to describe the relationship between data elements. For example, the name of the instrument used to generate the data or information defining a group of data subjects. Non-personal metadata will be available for public search online within the GHGA Data Infrastructure. Omics Data The Research Data collected as part of omics-based research. This research focuses on collecting information regarding the entire set of certain molecules in a sample. Within the context of GHGA, Omics Data linked to genetic information of an individual are of particular interest since in many cases omics data would fall under the definition of personal data in Art. 4 Nr. 1 GDPR. Types of Omics Data considered in GHGA are e.g.: genomics \u2013 the entirety of the hereditary information in a sample\u2019s DNA; transcriptomics \u2013 the entirety of the RNA transcribed from DNA; epigenomics \u2013 information on epigenetic modifications of the genetic materials. Person authorised to Act Individuals that are authorised to act on behalf of a 6251a85a-47d0-11ee-be56-0242ac120002:c9c92dc6464340840f3b2dd8b311c1d6:&lt;__None__&gt; as defined in the 6251a85a-47d0-11ee-be56-0242ac120002:e0167294a7df3d15d7f8ec69f41f3c9a:&lt;__None__&gt; between the RDC and 6251a85a-47d0-11ee-be56-0242ac120002:8027622a47132b3b5c4b90441838baf6:&lt;__None__&gt;. For details see here. Personal Metadata Information that describes or annotates research data to facilitate its interpretation or to describe the relationship between data elements. For example, demographic data or information on the ancestry of the data subjects of the research data that allow conclusions to be drawn about individuals and thus fall within the scope of the GDPR, Art. 4 No. 1 GDPR. Personal metadata are made available to the data requester together with the research data only under controlled access after release by the data submitter. Research Data Controller (RDC) Institution that is the controller (as defined by the GDPR) of Research Data and that contracted GHGA for processing the Research Data on their behalf. The term is also used for the corresponding party if the processing of the Research Data is only intended, i.e. before such a contract is established. Research Data Controller Representative (RDCR) Natural person representing the Research Data Controller when establishing the contractual relationship with GHGA. Research Data Submitter (RDSU) Natural person authorised by the Research Data Controller to peform the upload of Metadata and Research Data on behalf of the Research Data Controller. Research Data Omics or other forms of genetic (Art. 4 Nr. 13 GDPR) and health data (Art. 4 Nr. 15 GDPR) that are used for scientific research purposes. This is considered to be special category personal data under Art. 9 (1) in conjunction with Art. 4 Nr. 1 GDPR. Research Ethics Committee Committee at an institution that conducts independent ethics reviews of research projects involving human subjects, their samples, or data. Research Ethics Committees assume the formal role of approving (or rejecting) research projects on the basis that they comply (or fail to comply) with relevant research ethics standards, especially regarding the protection of research subjects' privacy and well-being. Sometimes also called an Institutional Review Board. Service User Person who is contacting the GHGA Helpdesk for any form of user support. Submission Reviewer (SR) Natural person authorised by the Research Data Controller to review a data upload before the submission is finalized and eventually made publicly findable by GHGA."},{"location":"cli_tools/cli_overview/","title":"Overview","text":"<p>The GHGA CLI (command-line interface) tools provide command-line utilities and Python libraries to facilitate interaction with GHGA's data infrastructure. These tools support tasks such as securely downloading encrypted files, converting metadata formats, and validating metadata.</p>"},{"location":"cli_tools/cli_overview/#available-tools","title":"Available Tools:","text":"<ul> <li>GHGA Connector \u2013 Securely download and decrypt files from the GHGA infrastructure.</li> <li>GHGA Transpiler \u2013 Convert metadata from XLSX spreadsheets into JSON format, ensuring compatibility with GHGA systems.</li> <li>GHGA Validator \u2013 Validate metadata against the GHGA Metadata Model and generate a compliance report.</li> </ul>"},{"location":"cli_tools/connector/","title":"GHGA Connector","text":"<p>The GHGA Connector is a command line tool and Python library facilitating interaction with the file storage infrastructure of GHGA. Currently, it provides functionality for downloading and decrypting files.</p>"},{"location":"cli_tools/connector/#installation-and-upgrade","title":"Installation and Upgrade","text":"<p>We recommend installing / upgrading to the latest version of the GHGA connector using pip.</p> <p>Install or upgrade: <pre><code>pip install --upgrade ghga-connector\n</code></pre></p>"},{"location":"cli_tools/connector/#crypt4gh-keys","title":"Crypt4gh Keys","text":"<p>GHGA Connector requires a Crypt4GH key pair to download data. Please create a pair of Crypt4GH keys if you don't already have one. The public key is also needed for the creation of the download token through the Data Portal.</p> <p>By default, GHGA Connector looks for the keys at ./key.pub and ./key.sec. You can either place your keys there or use CLI options to specify your key locations.</p>"},{"location":"cli_tools/connector/#usage","title":"Usage","text":"<pre><code>Usage: ghga-connector [OPTIONS] COMMAND [ARGS]...\n\nOptions:\n  --install-completion [bash|zsh|fish|powershell|pwsh]\n                                  Install completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\n                                  Show completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n\nCommands:\n  decrypt   Command to decrypt a downloaded file\n  download  Command to download files\n</code></pre>"},{"location":"cli_tools/connector/#download","title":"Download","text":"<p>The <code>download</code> command is used to download files. In order to download files, you must provide a download token, which contains both the download instructions and authentication details.</p> <p>Download command usage: <pre><code>Usage: ghga-connector download [OPTIONS]\n\n  Command to download files\n\nOptions:\n  --output-dir PATH           The directory to put the downloaded files into.\n                              [required]\n  --my-public-key-path PATH   The path to a public key from the Crypt4GH key\n                              pair that was announced when the download token\n                              was created. Defaults to key.pub in the current\n                              folder.  [default: ./key.pub]\n  --my-private-key-path PATH  The path to a private key from the Crypt4GH key\n                              pair that was announced when the download token\n                              was created. Defaults to key.sec in the current\n                              folder.  [default: ./key.sec]\n  --help                      Show this message and exit.\n</code></pre></p>"},{"location":"cli_tools/connector/#download-token","title":"Download Token","text":"<p>GHGA Connector requires a download token to authenticate and process your request against GHGA Central. Each download request - which may comprise multiple files - is represented by a download token, which should be created via the GHGA Data Portal. For further information on how to create a download token, please refer to the Data Download documentation.</p>"},{"location":"cli_tools/connector/#download-examples","title":"Download Examples","text":"<ol> <li>To download a dataset: <pre><code>ghga-connector download --output-dir &lt;OUTPUT-DIR&gt;\n</code></pre> You will then be asked to provide the download token: <pre><code>Please paste the complete download token that you copied from the GHGA data portal: \n</code></pre> Paste the download token you created via the GHGA data portal and the download process will be initiated.</li> </ol>"},{"location":"cli_tools/connector/#decrypt","title":"Decrypt","text":"<p>The files you download are encrypted. To decrypt a file, please use the <code>decrypt</code> command.</p> <p>Decrypt command usage: <pre><code>Usage: ghga-connector decrypt [OPTIONS]\n\n  Command to decrypt a downloaded file\n\nOptions:\n  --input-dir PATH            Path to the directory containing files that\n                              should be decrypted using a common decryption\n                              key.  [required]\n  --output-dir PATH           Optional path to a directory that the decrypted\n                              file should be written to. Defaults to input\n                              dir.\n  --my-private-key-path PATH  The path to a private key from the Crypt4GH key\n                              pair that was announced when the download token\n                              was created. Defaults to key.sec in the current\n                              folder.  [default: ./key.sec]\n  --help                      Show this message and exit.\n</code></pre></p>"},{"location":"cli_tools/connector/#decrypt-examples","title":"Decrypt Examples","text":"<ol> <li>To decrypt files: <pre><code>ghga-connector decrypt --input-dir &lt;INPUT-DIR&gt;\n</code></pre></li> </ol>"},{"location":"cli_tools/transpiler/","title":"GHGA Transpiler","text":"<p>The GHGA Transpiler is a Python library and command line utility to transpile the official GHGA metadata XLSX workbooks to JSON. Please note that the GHGA Transpiler does not validate that the provided metadata is compliant with the GHGA Metadata Schema. This can be achieved by running the GHGA Validator on the JSON data generated by the GHGA Transpiler.</p>"},{"location":"cli_tools/transpiler/#installation-and-upgrade","title":"Installation and Upgrade","text":"<p>We recommend installing the latest version of the GHGA transpiler using pip.</p> <p>Install: <pre><code>pip install ghga-transpiler\n</code></pre></p> <p>Upgrade: <pre><code>pip install --upgrade ghga-transpiler\n</code></pre></p>"},{"location":"cli_tools/transpiler/#usage","title":"Usage","text":"<pre><code>Usage: ghga-transpiler [OPTIONS] SPREAD_SHEET [OUTPUT_FILE]\n\n\nArguments:\n  SPREAD_SHEET   The path to input file (XLSX)  [required]\n  [OUTPUT_FILE]  The path to output file (JSON).\n\nOptions:\n  -f, --force                     Override output file if it exists.\n  --install-completion [bash|zsh|fish|powershell|pwsh]\n                                  Install completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\n                                  Show completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli_tools/transpiler/#examples","title":"Examples","text":"<p> Example data can be downloaded from https://github.com/ghga-de/example-data/</p> <ol> <li>To transpile <code>metadata.xlsx</code>: <pre><code>ghga-transpiler metadata.xlsx metadata.json\n</code></pre></li> <li>To use the same output name (<code>/work_directory/output.json</code>) in another run: <pre><code>ghga-transpiler --force another_metadata.xlsx another_metadata.json\nghga-transpiler -f another_metadata.xlsx another_metadata.json\n</code></pre></li> <li>To display help message: <pre><code>ghga-transpiler --help\n</code></pre></li> </ol>"},{"location":"cli_tools/validator/","title":"GHGA Validator","text":"<p>GHGA Validator is a command line utility to validate metadata w.r.t. its compliance to the GHGA Metadata Model. It takes metadata encoded in JSON or YAML format and produces a validation report in JSON format.</p> <p>There is a possibility to indicate the root class for validation. In case it was not specified, it will induced from the schema.</p> <p>Currently the following validation types are included in GHGA Validator:</p> <ul> <li>Structural validation of a JSON object</li> <li>Validation of the non inline references</li> <li>Uniqueness of the fields defined as identifier/unique key</li> </ul>"},{"location":"cli_tools/validator/#installation-and-upgrade","title":"Installation and Upgrade","text":"<p>We recommend installing the latest version of the GHGA transpiler using pip.</p> <p>Install: <pre><code>pip install ghga-validator\n</code></pre></p> <p>Upgrade: <pre><code>pip install --upgrade ghga-validator\n</code></pre></p>"},{"location":"cli_tools/validator/#usage","title":"Usage","text":"<pre><code>Usage: ghga-validator [OPTIONS]\n\n\nOptions:\n  -s, --schema PATH               Path to metadata schema (modelled using\n                                  LinkML)  [required]\n  -i, --input FILE                Path to submission file in JSON format to be\n                                  validated  [required]\n  -r, --report FILE               Path to resulting validation report\n                                  [required]\n  --target-class TEXT             The root class name\n  --install-completion [bash|zsh|fish|powershell|pwsh]\n                                  Install completion for the specified shell.\n  --show-completion [bash|zsh|fish|powershell|pwsh]\n                                  Show completion for the specified shell, to\n                                  copy it or customize the installation.\n  --help                          Show this message and exit.\n</code></pre>"},{"location":"cli_tools/validator/#examples","title":"Examples","text":"<p> Example data can be downloaded from https://github.com/ghga-de/example-data/</p> <p> The latest version of the GHGA metadata schema (<code>submission.yaml</code>) can be downloaded from https://github.com/ghga-de/ghga-metadata-schema/releases/latest</p> <ol> <li>To validate <code>data.json</code> against the schema <code>submission.yaml</code> and store the validation report into the file <code>report.json</code>: <pre><code>ghga_validator --input data.json --schema submission.yaml --report report.json\n</code></pre></li> <li>To validate with providing the root class <code>Submission</code> for validation: <pre><code>ghga_validator --input data.json --schema submission.yaml --report report.json --target-class Submission\n</code></pre></li> <li>To display help message: <pre><code>ghga_validator --help\n</code></pre></li> </ol>"},{"location":"metadata/entities/","title":"Captured Metadata","text":"<ul> <li>Research Metadata \u2013 Covers metadata on individuals, samples, experiments, and analyses, including biospecimens, experimental methods, and analytical workflows used to generate the data.</li> <li>Administrative Metadata \u2013 Manages data governance, access, and study details, defining datasets, access policies, responsible committees, and linked publications.</li> <li>Submission Spreadsheet \u2013 Provides a structured format for metadata submission, ensuring consistency and completeness across all metadata categories.</li> </ul> <p>A breakdown of each metadata element described in the different entities will provide more insight on what elements are required for the functionality of GHGA, mandatory properties and recommended or optional information that can be provided by the data submitters.</p>"},{"location":"metadata/entities/#research-metadata","title":"Research Metadata","text":"<p>The Research Metadata focuses on the reusability and FAIRness of the data. The Research Metadata encapsulates a set of classes that shape the model in accordance to the performed experiment ensuring reproducibility and scalability. The classes include Individual, Biospecimen/Sample, Experiment, Experiment Method, Analysis and Analysis Method.</p>"},{"location":"metadata/entities/#individual","title":"Individual","text":"<p>The Individual entity collects non-personal metadata about the Individual from which the samples were collected. The content of the Individual entity is crucial to identify cohorts of interest and gives valuable insight on the target group of an experiment. </p>"},{"location":"metadata/entities/#individual-metadata-properties","title":"Individual metadata properties","text":"<p>In order to describe an Individual, data submitters are required to provide information about sex and are recommended to provide information about phenotypic features and diagnoses. Additional information about the geographical region and ancestries can also be provided.</p> <p>The Individual entity is linked to the Sample entity.</p>"},{"location":"metadata/entities/#individual-supporting-file","title":"Individual Supporting File","text":"<p>If the data submitters have additional information to provide about the Individual, then they can make use of the Individual Supporting File class. </p>"},{"location":"metadata/entities/#individual-supporting-file-metadata-properties","title":"Individual Supporting File metadata properties","text":"<p>The Individual Supporting File requires the following information: file format, file name, dataset associated with this file as well as if the file is included as part of the submission.</p>"},{"location":"metadata/entities/#sample","title":"Sample","text":"<p>The Sample describes the extracted sample and tissue for an experimental process. Furthermore, the Sample is defined as a limited quantity of something to be used for testing, analysis, inspection, investigation, demonstration, or trial use. A sample is prepared from a biospecimen (isolate or tissue). The Sample entity includes slots describing the Biospecimen from which the sample was prepared, which are highlighted with a \"biospecimen_\" -prefix. The Biospecimen is defined as any natural material taken from a biological entity for testing, diagnostics, treatment or research purposes.</p> <p>The Sample is linked to the Individual entity describing the collection of biological material. Further, it is linked to the Experiment.</p>"},{"location":"metadata/entities/#sample-metadata-properties","title":"Sample metadata properties","text":"<p>The Sample entity requires data submitters to provide the name, description, whether the sample is case or control, as well as the alias to the Individual from which the Sample was derived. In addition to the mandatory information, the data submitter is recommended to provide information about the storage, whether the sample can be classified as  diseased or healthy, and biological replicate information. Other optional fields include the type of the sample and an EGA accession ID. </p> <p>To further describe the Biospecimen from which the sample was prepared, data submitters are required to provide information about the age of the individual at the time of sampling and the biospecimen tissue. The recommended properties include a name for the biospecimen, its type, the vital status of the individual at the time of sampling, and the biospecimen isolation and storage.</p>"},{"location":"metadata/entities/#experiment","title":"Experiment","text":"<p>An Experiment is an investigation that consists of a coordinated set of actions and observations designed to generate data with the goal of verifying, falsifying, or establishing the validity of a hypothesis. The Experiment entity describes the experimental setup or a protocol used for performing an omics experiment. </p> <p>The Experiment entity is linked to the Sample which implies one or more samples associated with this Experiment and the Experiment Method which implies one or more experiment methods associated with this Experiment. The outcome of an Experiment results in Research Data File.</p>"},{"location":"metadata/entities/#experiment-metadata-properties","title":"Experiment metadata properties","text":"<p>The Experiment entity requires the data submitters to provide information about experiment method, title, description and sample information.</p>"},{"location":"metadata/entities/#experiment-method","title":"Experiment Method","text":"<p>The Experiment Method entity captures information about the protocol that was followed to perform the omics experiment.</p>"},{"location":"metadata/entities/#experiment-method-metadata-properties","title":"Experiment Method metadata properties","text":"<p>The data submitter is required to provide information about the name, description, library type, selection methods, preparation, the instrument model and sequencing layout to fulfil the Experiment Method pertaining to an omics experiment. Furthermore, it is recommended to provide information about the library preparation kit name and manufacturer, the primer, end bias, flow cell ID and type, rna seq strandedness, sample barcode read and sequencing center. The optional properties include target region, target coverage and EGA accession ID.</p>"},{"location":"metadata/entities/#experiment-method-supporting-file","title":"Experiment Method Supporting File","text":"<p>Any additional information pertaining to the Experiment Method can be provided as Experiment Method Supporting File. </p>"},{"location":"metadata/entities/#experiment-method-supporting-file-metadata-properties","title":"Experiment Method Supporting File metadata properties","text":"<p>The submitter is required to provide information about the file format, the Experiment Method this file supports, the file name, the Dataset associated with this file and whether this file is included as part of the submission.</p>"},{"location":"metadata/entities/#research-data-file","title":"Research Data File","text":"<p>The Research Data File entity is generated as a result of a direct measurement or sequencing of a sample. They are the raw files that were generated while carrying out an Experiment. This entity is linked to the Experiment that produced this file as well as the Dataset that is associated with this file. The GHGA metadata model emphasizes on the submission of a Research Data File alone or accompanied by Process Data Files for enabling reconstruction of the analytical process representing a submission.</p>"},{"location":"metadata/entities/#research-data-file-metadata-properties","title":"Research Data File metadata properties","text":"<p>The Research Data File entity requires a data submitter to provide information about the file format, technical replicate, the Experiment that generated this Research Data File, the file name, the Dataset and whether the file is included in the submission. It is also recommended to provide information about the sequencing lane. The EGA accession ID is an optional property.</p>"},{"location":"metadata/entities/#analysis","title":"Analysis","text":"<p>The Analysis entity permutates a Research Data File into a Process Data File through a computational workflow. </p> <p>The Analysis entity is linked to Experiment via Research Data File and also linked to Analysis Method.</p>"},{"location":"metadata/entities/#analysis-metadata-properties","title":"Analysis metadata properties","text":"<p>The data submitter is required to provide information about the Analysis title, the Analysis Method that is associated with this Analysis and the Research Data Files that this Analysis used as input to generate Process Data Files.</p>"},{"location":"metadata/entities/#analysis-method","title":"Analysis Method","text":"<p>The Analysis Method entity describes the computational workflow that created Process Data Files in more detail. </p>"},{"location":"metadata/entities/#analysis-method-metadata-properties","title":"Analysis Method metadata properties","text":"<p>For this submission, the data submitter is required to provide information about the Analysis Method name, a description, type, the workflow name, workflow repository and workflow DOI. Furthermore, it is also recommended to provide information about the workflow version, workflow tasks, parameters and software versions.</p>"},{"location":"metadata/entities/#analysis-method-supporting-file","title":"Analysis Method Supporting File","text":"<p>For any additional information pertaining to the Analysis Method entity, the data submitter can use the Analysis Method Supporting File.</p>"},{"location":"metadata/entities/#analysis-method-supporting-file-properties","title":"Analysis Method Supporting File properties","text":"<p>For supporting information about the Analysis Method, the data submitter is required to provide information about the file format, the Analysis Method this file supports, the file name, and the Dataset associated with this file.</p>"},{"location":"metadata/entities/#process-data-file","title":"Process Data File","text":"<p>The Process Data File entity is a generated outcome of an analysis, alignment or  processing of a Research Data File. The Process Data File entity is linked to the Dataset that is associated with the file and the Analysis that produced this Process Data File.</p>"},{"location":"metadata/entities/#process-data-file-metadata-properties","title":"Process Data File metadata properties","text":"<p>The Process Data File entity requires the data submitter to provide information about the file format, the Analysis from which this file originated, the file name, and the Dataset. Additionally, it is also possible to submit an optional EGA accession ID.</p> <p>The submission process allows submission of processed data file alone but this is discouraged as it requires creation of empty Experiment class.</p>"},{"location":"metadata/entities/#administrative-metadata","title":"Administrative Metadata","text":"<p>The Administrative Metadata focuses on managing the resources such as creation or acquisition of the data, rights management, and disposition. </p>"},{"location":"metadata/entities/#dataset","title":"Dataset","text":"<p>GHGA presents its content to potential data requesters and submitters with the Dataset entity, which focuses on sharing functionality by describing the contents at a high level. Each Dataset is linked to a Data Access Policy, which builds the legal basis for the sharing of data. One Dataset has links to Experiment via Research Data File, and to  Analysis via Process Data File. The Dataset is also indirectly linked to Analysis Method, Experiment Method and the Individual via Analysis Method Supporing File, Experiment Method Supporing File and Individual Supporting File, respectively. The Dataset entity is also linked to Study.</p>"},{"location":"metadata/entities/#dataset-metadata-properties","title":"Dataset metadata properties","text":"<p>The Dataset entity is aimed at capturing relevant information about a dataset itself. The mandatory information required for Dataset entity includes title, description, type, the Data Access Policy that regulates this Dataset and the Study. Optionally, the data submitter could also provide information about an EGA accession.</p>"},{"location":"metadata/entities/#data-access-policy-and-committee","title":"Data Access Policy and Committee","text":"<p>Depositing data at GHGA requires a data submitter to provide a Data Access Committee (DAC) and Data Access Policy (DAP). This ensures controlled access to their deposited data and a clear guideline for data requesters to access the data. This includes a defined contact person and a consent-based legal basis for getting access to a dataset. The DAP entity is linked to Dataset and DAC.</p>"},{"location":"metadata/entities/#dap-and-dac-metadata-properties","title":"DAP and DAC metadata properties","text":"<p>A DAP is directly linked to the DAC and Dataset entity, thus providing  the condition under which the data deposited at GHGA can be re-used by a data requester. The submitter must provide an alias, name, description and either the policy text for the DAP or the URL where the DAP is stored, data use permission and modifier using the Data Use Ontology, and the DAC that governs this DAP.</p> <p>A DAC is linked directly to DAP and requires information about the DAC email and institute and optionally about an EGA accession.</p>"},{"location":"metadata/entities/#study","title":"Study","text":"<p>All data deposited at GHGA is subject to a specific study, under which relevant data has been aggregated. A Study is an experimental investigation of a particular phenomenon and involves a detailed examination and analysis of a subject to learn more about the phenomenon being studied. A detailed description of a study can guide data requesters to identify the most relevant datasets for their own research.  The Study entity is linked to Dataset and optionally to Publication.</p>"},{"location":"metadata/entities/#study-metadata-properties","title":"Study metadata properties","text":"<p>In order to describe a Study, data submitters are required to provide information about the study affiliation(s), the title, a description and the study type. Optionally, they can provide an EGA accession ID.</p>"},{"location":"metadata/entities/#publication","title":"Publication","text":"<p>The Publication entity refers to a journal article, book, or conference paper that presents original research or scholarly findings in a specific field of study, contributing to the collective knowledge and understanding of that discipline. </p> <p>The Publication entity is linked to Study.</p>"},{"location":"metadata/entities/#publication-metadata-properties","title":"Publication metadata properties","text":"<p>The data submitter is required to provide information about the Study associated with this publication. Optionally, the data submitter can also provide information about the publication title, abstract, author, year, journal and DOI.</p>"},{"location":"metadata/entities/#submission-spreadsheet","title":"Submission Spreadsheet","text":"<p>The Submission Spreadsheet for GHGA Archive captures the above-mentioned metadata in an ordered fashion. The submission process is tailored to replicate a \u201cfront-to-end\u201d workflow:</p> <ul> <li>Which individuals are subject to investigation?</li> <li>Which biological material was collected and how?</li> <li>Which experiment was performed and how? Which files were generated as result?</li> <li>Which analysis was performed and how? Which output files were generated from which input files?</li> <li>How can this data be shared in meaningful datasets? Which conditions apply and who governs them?</li> </ul> <p>The submitter can also make use of the supporting files to enrich their data with additional information, such as experimental protocols for the Experiment class or workflow parameter files for the Analysis class. The supporting files can contain structured metadata, such as Phenopackets or PED files for the Individual class. Since supplementary files are encrypted and inaccessible without DAC approval, this allows submissions of clinical or personal metadata that can only be accessed by requesters after signing a Data Transfer Agreement. Hence, the metadata model can only indicate the presence of supplementary files for classes and signify that a submission contains additional information but not process their content. This results in a submission process, which will appear much more natural to submitters, while maintaining a high degree of flexibility to adapt to different omics types.</p>"},{"location":"metadata/ghga_submission_full.xlsx/","title":"Submission","text":""},{"location":"metadata/ghga_submission_full.xlsx/#ghga_submission_fullxlsx","title":"ghga_submission_full.xlsx","text":""},{"location":"metadata/ghga_submission_full.xlsx/#submission-components","title":"Submission components:","text":"<p>Study worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Study.md</p> <p>Individual worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Individual.md</p> <p>IndividualSupportingFile worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/IndividualSupportingFile.md</p> <p>Sample worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Sample.md</p> <p>ExperimentMethod worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/ExperimentMethod.md</p> <p>ExperimentMethodSupportingFile worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/ExperimentMethodSupportingFile.md</p> <p>Experiment worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Experiment.md</p> <p>ResearchDataFile worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/ResearchDataFile.md</p> <p>AnalysisMethod worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/AnalysisMethod.md</p> <p>AnalysisMethodSupportingFile worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/AnalysisMethodSupportingFile.md</p> <p>Analysis worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Analysis.md</p> <p>ProcessDataFile worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/ProcessDataFile.md</p> <p>Dataset worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Dataset.md</p> <p>DataAccessPolicy worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/DataAccessPolicy.md</p> <p>DataAccessCommittee worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/DataAccessCommittee.md</p> <p>Publication worksheet: * https://ghga-de.github.io/docs/metadata/worksheets/Publication.md</p>"},{"location":"metadata/overview/","title":"The GHGA Metadata Model","text":"<p>The GHGA Metadata Model provides a structured approach to organising human omics data, ensuring FAIR principles (Findable, Accessible, Interoperable, Reusable) for data archiving and sharing. This documentation offers in-depth explanations of the metadata model, including its structure, captured metadata, standards, and ontologies.</p>"},{"location":"metadata/overview/#key-components","title":"Key Components:","text":"<ol> <li>Introduction \u2013 Understand the general structure of the metadata model and how it supports data submission and retrieval.</li> <li>Captured Metadata \u2013 Learn about types of metadata captured in our model, including research and administrative metadata attributes.</li> <li>Concepts &amp; Standards \u2013 Read about the internationally recognised standards and ontologies for interoperability and data harmonisation on which the GHGA metadata model is based.</li> <li>Data Dictionary - Find detailed definitions of metadata terms used in the GHGA schema.</li> </ol>"},{"location":"metadata/overview/#glossary","title":"Glossary","text":"<ul> <li> <p>Entity: An Entity holds characteristics of a real-world object. Example: The Individual entity is described by the information (properties) for sex, year of birth and height.</p> <ul> <li>Synonyms: class, table, object</li> </ul> </li> <li> <p>Property: A Property is a single characteristic that can be used in combination with other characteristics to describe a real-world object. Example: The combination of the properties sex, year of birth and height describe the (real-world object) entity Individual.</p> <ul> <li>Synonyms: attribute, element, field, slot</li> </ul> </li> <li> <p>FAIR: Findable, Accessible, Interoperable, Reusable</p> </li> </ul>"},{"location":"metadata/overview/#introduction","title":"Introduction","text":"<p>The German Human Genome-Phenome Archive (GHGA) provides a nation-wide resource for archiving, accessing and sharing of multi-omics data produced and processed in research and health care initiatives in Germany. GHGA aims to bring these data together and make it easier to find data for secondary use, by adopting and adhering to FAIR data principles. In order to meet the domain-specific requirements we developed the GHGA Metadata Schema - a schema for representing information pertaining to various aspects of our data.</p> <p>This documentation serves as the description and reasoning behind the Metadata Model of GHGA, which encapsulates the metadata schema, its technical implementation, and resources to support submission of metadata. The Archive function of GHGA is envisioned to handle a wide variety of omics and research data. The GHGA metadata model aims at facilitating  comprehensive submissions that maximize the amount of collected metadata without creating friction on the submitter side, enabling (reusable) submissions of different types of -omics data into GHGA. This metadata model can satisfy the heterogeneous needs of submitters while maintaining the FAIR principles, interoperability with EGA and facilitating streamlined user journeys.</p> <p>Classes in the schema can be grouped into Research Metadata and Administrative Metadata based on the information they capture. The Research Metadata aims at maximising the reusability and FAIRness of the data, while the Administrative Metadata focuses on managing the resources, such as creation or acquisition of the data, rights management, and disposition. The Research Metadata classes include Individual, Biospcimen/Sample, Experiment, Experiment Method, Analysis and Analysis Method. The Administrative Metadata captures Dataset, Data Access Policy, Data Access Committee, Publication, and Study.  </p> <p>The model also differentiates between three file types:</p> <ul> <li>Research Data File: A file which results from the omics experiment, such as sequencing of a sample.</li> <li>Process Data File: A file that is generated as output from an analysis performed on a Research Data File, such as alignment or processing.</li> <li>Supporting File: A file that provides further information about an Individual, Experiment Method or Analysis Method. These could be unstructured protocols or structured information, such as Phenopackets or BioCompute Objects.</li> </ul> <p>Furthermore we provide data submitters with a Submission Spreadsheet in order to easily deposit their data within GHGA.</p>"},{"location":"metadata/standards/","title":"Concepts and Standards","text":"<ul> <li>Resources and Standards - Guiding principles and frameworks for data accessibility, reproducibility, and secure sharing across research domains, ensuring consistency, reliability, and ethical data management.</li> <li>Metadata Standards - Providing a structured approach to describing and organising research data, ensuring consistency across datasets and facilitating reuse.</li> <li>Ontologies - Standardised terminology across datasets to improve metadata quality and enhance data interoperability and integration.</li> </ul> <p>GHGAs metadata model follows several internationally renowned concepts, standards, and resources to provide a metadata schema to share data in a standardized and harmonized fashion.</p>"},{"location":"metadata/standards/#resources-and-standards","title":"Resources and Standards","text":""},{"location":"metadata/standards/#fair-data-principles","title":"FAIR Data Principles","text":"<p>While digitization is becoming more and more important and technologies accelerate constantly, NGS experiments and measurements produce large quantities of data. Every single dataset in this huge amount of data should be findable and usable for humans and computers equally. In 2016, a conglomerate of representatives of different disciplines - such as academia, industry, funding agencies and scholarly publishers - published the \"FAIR Guiding principles for scientific data management and stewardship\". These principles provide guidance on what to consider when data is published so that an automated and individual exploration, sharing, and reusing of the data is possible. FAIR data should be:  Findable, Accessible, Interoperable and Reusable.</p>"},{"location":"metadata/standards/#fairsharing","title":"FAIRsharing","text":"<p>Thousands of standards, ontologies and vocabularies have been developed for a variety of communities in order to guide reproducible research. A central database for FAIR standards, repositories and standards is FAIRsharing. The mission of the FAIRsharing community is to evaluate standards, databases, policies, and collections. These can be queried by the user\u2019s specific field of interest and can be categorized by Maintained / Not Maintained, Recommended / Not Recommended and Ready / Deprecated / Uncertain / In Dev.</p>"},{"location":"metadata/standards/#global-alliance-for-genomics-health-ga4gh","title":"Global Alliance for Genomics &amp; Health (GA4GH)","text":"<p>The Global Alliance for Genomics and Health (GA4GH) is a worldwide acknowledged standards body established to promote globally responsible data sharing of genomic and health-related data. The main objective of this initiative is the alliance of researchers, data scientists, healthcare providers and practitioners and other authorized users while protecting competing interests. GA4GH enables federated data sharing models while preserving the data security, ethical and regulatory framework as well as data authorization and access of sensitive data. Data sharing standards offer data providers the confidence and trust on the data being accessed in accordance with their data policies and without losing control over the multiple downloads of data.</p>"},{"location":"metadata/standards/#genomic-data-commons","title":"Genomic Data Commons","text":"<p>The Genomic Data Commons (GDC) was established by the National Cancer Institute (NCI) to boost the understanding of \"large-scale, multidimensional data\". Therefore the GDC generates datasets to systematize human tumor variations, especially encouraging the unification and sharing of data.  GDC provides the cancer research community with a unified repository and cancer knowledge base that enables data sharing across cancer genomic studies in support of precision medicine. The GDC Data Dictionary is a resource that describes the GDC data model which includes clinical, biospecimen, administrative, and genomic metadata that can be used in parallel with the genomic data generated by the GDC. The properties and the values in the GDC data dictionary contain references to external standards which are defined and maintained by NCI Thesaurus (NCIt) and the Cancer Data Standards Registry and Repository (caDSR).</p>"},{"location":"metadata/standards/#metadata-standards","title":"Metadata standards","text":"<p>Metadata provides context and provenance to raw data and methods and are essential to both discovery and validation. It can be classified as a high level document which establishes a common way of structuring and understanding data by including principles and implementation issues utilizing the standard. Metadata standards offer conventions for the generation and description of research data. They specify and define the structure of metadata.</p>"},{"location":"metadata/standards/#minimum-information-about-a-high-throughput-nucleotide-sequencing-experiment-minseqe","title":"Minimum Information about a high-throughput Nucleotide Sequencing Experiment (MINSEQE)","text":"<p>MINSEQE describes the minimum information about a high-throughput nucleotide sequencing experiment that is needed to enable the unambiguous interpretation and facilitate reproduction of the results of the experiment. By analogy to the MIAME guidelines for microarray experiments, adherence to the MINSEQE guidelines will improve integration of multiple experiments across different modalities, thereby maximizing the value of high-throughput research. The five main elements of experimental description to be MINSEQUE compliant include - description of the experiment and sample under study, sequence read data for each assay, final processed data for the study, information about experiment-sample relationship, experiment and sample processing protocol.</p>"},{"location":"metadata/standards/#ontologies","title":"Ontologies","text":"<p>To ensure that the metadata that is collected in GHGA is of high quality, we support a selection of ontologies for certain properties where their values can be one or more concept terms from these ontologies. The ontologies were chosen based on their suitability to represent the knowledge specific to genomic medicine. They have a wide adoption and community support, which increases their interoperability and reusability.</p>"},{"location":"metadata/standards/#brenda-tissue-ontology","title":"BRENDA Tissue Ontology","text":"<p>The BRENDA Tissue Ontology (BTO) provides a structured controlled vocabulary to describe the source of an enzyme. The ontology contains terms to represent tissues, cell lines, cell types and cell cultures. These terms span uni- and multicellular organisms. We recommend the use of concepts from BTO to represent anatomical location/site associated with a Biospecimen and/or a Sample. For example, instead of using free text \u2018heart tissue\u2019 to represent the site from which a Biospecimen was derived from, we would recommend using the appropriate concept BTO:0004293 heart endothelium.</p>"},{"location":"metadata/standards/#data-use-ontology","title":"Data Use Ontology","text":"<p>Endorsed by GA4GH, the Data Use Ontology (DUO) allows users to tag datasets with usage restrictions, allowing them to become automatically discoverable based on a health, clinical, or biomedical researcher\u2019s authorization level or intended use. We recommend the use of concepts from DUO to represent the use restrictions associated with a Dataset. For example, instead of having use restrictions as free text in a Data Access Policy, we would recommend using the appropriate concepts from DUO to better represent the granularity of use conditions and restrictions.</p>"},{"location":"metadata/standards/#human-ancestry-ontology","title":"Human Ancestry Ontology","text":"<p>The Human Ancestry Ontology (HANCESTRO) provides a systematic description of the ancestry concepts. HANCESTRO was originally built for NHGRI-GWAS Catalog and has since then been used by other consortia like the GA4GH, and the Human Cell Atlas. We recommend the use of concepts from HANCESTRO to represent the ancestry of an Individual. For example, instead of using \u2018European ancestry\u2019 to represent the ancestry of an Individual, we would recommend using the appropriate concept HANCESTRO:0005 European.</p>"},{"location":"metadata/standards/#human-phenotype-ontology","title":"Human Phenotype Ontology","text":"<p>The Human Phenotype Ontology (HPO) provides a standardized vocabulary of phenotypic abnormalities encountered in human disease. HPO is used by various consortia like the GA4GH, Solve-RD, and IRDiRC. We recommend the use of concepts from HPO to represent phenotypic abnormalities that characterize a Biospecimen and/or an Individual. For example, instead of using free text \u2018Heart attack\u2019 to represent an Individual who has suffered from a heart attack, we would recommend using the appropriate concept HP:0001658 Myocardial infarction.</p>"},{"location":"metadata/standards/#international-classification-of-diseases","title":"International Classification of Diseases","text":"<p>The International Classification of Diseases (ICD) is widely used across the world and is a crucial source of information on the prevalence, causes, and outcomes of human disease and mortality. Through the use of standardized coding, clinical information can be collected and recorded using ICD in primary, secondary, and tertiary care settings, as well as on death certificates. These data form the foundation for disease surveillance and statistical analysis, which inform healthcare planning, payment systems, quality control, and research. In addition, ICD's diagnostic categories facilitate consistent data collection and enable large-scale research studies. We recommend the use of classifications from ICD to represent a diagnosis associated with an Individual. For example, instead of using free text \u2018Malignant neoplasm of thymus\u2019 to represent that an Individual suffers from thymic carcinoma, we would recommend using the appropriate concept C37 Malignant neoplasm of thymus.</p>"},{"location":"metadata/standards/#mondo-disease-ontology","title":"Mondo Disease Ontology","text":"<p>The Mondo Disease Ontology (Mondo) provides a unified disease terminology that yields precise equivalences between disease concepts across various terminologies like OMIM, Orphanet, EFO, and DOID. Mondo is used by several consortia like GA4GH, ClinGen, and Gabriella Miller Kids First. We recommend the use of concepts from Mondo to represent diseases associated with a Biospecimen and/or an Individual. For example, instead of using free text \u2018Myocardial infarction\u2019 to represent an Individual who has suffered from a heart attack, we would recommend using the appropriate concept MONDO:0005068 Myocardial infarction.</p>"},{"location":"metadata/standards/#national-cancer-institute-thesaurus","title":"National Cancer Institute Thesaurus","text":"<p>The National Cancer Institute Thesaurus (NCIt) is a reference terminology covering the cancer domain, including diseases, abnormalities, anatomy, drugs, genes, and more. It provides granular and consistent terminology in certain areas like cancer diseases and combination chemotherapies. The terminology is a combination from numerous cancer research domains and enables integration of information through semantic relationships. We recommend the use of concepts from NCIt to represent the case or control status associated with a Sample. For example, instead of using free text \u2018True Case Status\u2019 to represent the case status of a sample, we would recommend using the appropriate concept NCIT:C99269 True Case Status.</p>"},{"location":"metadata/data_dictionary/00_overview/","title":"Overview","text":"<p>The GHGA Data Dictionary provides precise definitions of terms used in the metadata schema. This alphabetical reference ensures clarity and consistency for data submitters and users.</p>"},{"location":"metadata/data_dictionary/Analysis/","title":"Analysis","text":""},{"location":"metadata/data_dictionary/Analysis/#description","title":"Description","text":"<p>An Analysis is a data transformation that transforms input data to output data.</p>"},{"location":"metadata/data_dictionary/Analysis/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Analysis/#analysis_method","title":"analysis_method","text":"<p>description : The alias of the Analysis Method that is associated with this Analysis. required : True data type : AnalysisMethod </p>"},{"location":"metadata/data_dictionary/Analysis/#title","title":"title","text":"<p>description : The title that describes an entity. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Analysis/#description_1","title":"description","text":"<p>description : A description summarizing how this Analysis was carried out (e.g., description of computational tools, pipelines, workflows). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Analysis/#type","title":"type","text":"<p>description : The type of this Analysis. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Analysis/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession of the 'Analysis' entity (EGAZ). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Analysis/#research_data_files","title":"research_data_files","text":"<p>description : One or more aliases of the Research Data Files that this Analysis used as input to create Process Data Files. required : True data type : ResearchDataFile </p>"},{"location":"metadata/data_dictionary/Analysis/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/","title":"AnalysisMethod","text":""},{"location":"metadata/data_dictionary/AnalysisMethod/#description","title":"Description","text":"<p>An Analysis Method captures the workflow steps that were performed to analyze data obtained from an Experiment.</p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/AnalysisMethod/#name","title":"name","text":"<p>description : A name identifying this Analysis Method. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#description_1","title":"description","text":"<p>description : Description of an entity. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#type","title":"type","text":"<p>description : The type of an entity. Note: Not to be confused with rdf:type. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#workflow_name","title":"workflow_name","text":"<p>description : The workflow name. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#workflow_version","title":"workflow_version","text":"<p>description : The workflow version. required : False data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#workflow_repository","title":"workflow_repository","text":"<p>description : The workflow repository (e.g., the URL). required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#workflow_doi","title":"workflow_doi","text":"<p>description : A digital object identifier for the workflow. Can be a publication or the workflow commit that was used for the Analysis. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#workflow_tasks","title":"workflow_tasks","text":"<p>description : Tasks performed by the workflow required : False data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#parameters","title":"parameters","text":"<p>description : Key/value pairs where key corresponds to a parameter name and value corresponds to a parameter value (e.g., 'aligner' = 'star_salmon',  'hisat2_build_memory' = '200.GB', 'split_fastq' = 50000000). required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#software_versions","title":"software_versions","text":"<p>description : key/value pairs where key corresponds to a software name and value corresponds to a version descriptor (e.g., <code>salmon</code> = '1.3.0', <code>trim-galore</code> = '0.6.6', <code>bedtools</code> = '2.29.2'). required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/AnalysisMethod/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/","title":"AnalysisMethodSupportingFile","text":""},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#description","title":"Description","text":"<p>An Analysis Method Supporting File is a File that contains additional information relevant for the Analysis Method, such as (unstructured) protocols or task descriptions.</p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#format","title":"format","text":"<p>description : The file format of the Supporting File (e.g., TXT, JSON). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CSV</code> <code>Tabular data represented as comma-separated values in a text file.</code> <code>JSON</code> <code>JavaScript Object Notation format; a lightweight, text-based format to represent tree-structured data using key-value pairs.</code> <code>PED</code> <code>The PED file describes individuals and genetic data and is used by the Plink package.</code> <code>TSV</code> <code>Tabular data represented as tab-separated values in a text file.</code> <code>TXT</code> <code>Textual format. Data in text format can be compressed into binary format, or can be a value of an XML element or attribute. Markup formats are not considered textual (or more precisely, not plain-textual).</code> <code>YAML</code> <code>YAML (YAML Ain't Markup Language) is a human-readable tree-structured data serialisation language.</code> <code>OTHER</code> <code>A file format not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#analysis_method","title":"analysis_method","text":"<p>description : The Analysis Process associated with an entity. required : True data type : AnalysisMethod </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#name","title":"name","text":"<p>description : The given filename. required : True data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#dataset","title":"dataset","text":"<p>description : The Dataset alias associated with this File. required : True data type : Dataset </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#included_in_submission","title":"included_in_submission","text":"<p>description : Whether a File is included in the Submission or not. required : True data type : boolean </p>"},{"location":"metadata/data_dictionary/AnalysisMethodSupportingFile/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessCommittee/","title":"DataAccessCommittee","text":""},{"location":"metadata/data_dictionary/DataAccessCommittee/#description","title":"Description","text":"<p>A group of members that are delegated to grant access to one or more datasets after ensuring the criteria for data sharing has been met,  and request for data use does not raise ethical and/or legal concerns.</p>"},{"location":"metadata/data_dictionary/DataAccessCommittee/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/DataAccessCommittee/#email","title":"email","text":"<p>description : The email of the Data Access Committee (e.g., DAC[at]email.com). This property must not include any personally identifiable data. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessCommittee/#institute","title":"institute","text":"<p>description : The Institute a person is affiliated with. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessCommittee/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessCommittee/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/","title":"DataAccessPolicy","text":""},{"location":"metadata/data_dictionary/DataAccessPolicy/#description","title":"Description","text":"<p>A Data Access Policy specifies under which circumstances, legal or otherwise, a user can have access to one or more Datasets belonging to one or more Studies.</p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/DataAccessPolicy/#name","title":"name","text":"<p>description : A name for this Data Access Policy. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#description_1","title":"description","text":"<p>description : A short description for this Data Access Policy. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#policy_text","title":"policy_text","text":"<p>description : The complete text for the Data Access Policy. required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#policy_url","title":"policy_url","text":"<p>description : An alternative to the Data Access Policy text is to provide the URL for the policy. This is useful if the terms of the policy are available online at a resolvable URL. required : False data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#data_use_permission_term","title":"data_use_permission_term","text":"<p>description : The Data Use Permission associated with this Data Use Policy. The used term should be a descendant of 'DUO:0000001: data use permission' (e.g., no restriction). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>GENERAL_RESEARCH_USE</code> <code>This data use permission indicates that use is allowed for general research use for any research purpose.</code> <code>HEALTH_OR_MEDICAL_OR_BIOMEDICAL_RESEARCH</code> <code>This data use permission indicates that use is allowed for health/medical/biomedical purposes; does not include the study of population origins or ancestry.</code> <code>DISEASE_SPECIFIC_RESEARCH</code> <code>This data use permission indicates that use is allowed provided it is related to the specified disease.</code> <code>NO_RESTRICTION</code> <code>This data use permission indicates there is no restriction on use.</code> <code>POPULATION_ORIGINS_OR_ANCESTRY_RESEARCH_ONLY</code> <code>This data use permission indicates that use of the data is limited to the study of population origins or ancestry.</code>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#data_use_permission_id","title":"data_use_permission_id","text":"<p>description : The DUO ID corresponding to the Data Use Permission term (e.g., DUO:0000004). required : True data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#data_use_modifier_terms","title":"data_use_modifier_terms","text":"<p>description : One or more Data Use Modifiers for the Data Use Permission associated with this Data Use Policy. The used terms should be descendants of 'DUO:0000017: data use modifier' (e.g., clinical care use). Please use 'USER_SPECIFIC_RESTRICTION' if no other modifier applies. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CLINICAL_CARE_USE</code> <code>This data use modifier indicates that use is allowed for clinical use and care.  Clinical Care is defined as Health care or services provided at home, in a healthcare facility or hospital. Data may be used for clinical decision making.</code> <code>RETURN_TO_DATABASE_OR_RESOURCE</code> <code>This data use modifier indicates that the requestor must return derived/enriched data to the database/resource.</code> <code>INSTITUTION_SPECIFIC_RESTRICTION</code> <code>This data use modifier indicates that use is limited to use within an approved institution.</code> <code>PROJECT_SPECIFIC_RESTRICTION</code> <code>This data use modifier indicates that use is limited to use within an approved project.</code> <code>USER_SPECIFIC_RESTRICTION</code> <code>This data use modifier indicates that use is limited to use by approved users.</code> <code>TIME_LIMIT_ON_USE</code> <code>This data use modifier indicates that use is approved for a specific number of months. This should be coupled with an integer value indicating the number of months.</code> <code>PUBLICATION_MORATORIUM</code> <code>This data use modifier indicates that requestor agrees not to publish results of studies until a specific date. This should be coupled with a date specified as ISO8601.</code> <code>GEOGRAPHICAL_RESTRICTION</code> <code>This data use modifier indicates that use is limited to within a specific geographic region. This should be coupled with an ontology term describing the geographical location the restriction applies to.</code> <code>ETHICS_APPROVAL_REQUIRED</code> <code>This data use modifier indicates that the requestor must provide documentation of local IRB/ERB approval.</code> <code>COLLABORATION_REQUIRED</code> <code>This data use modifier indicates that the requestor must agree to collaboration with the primary study investigator(s). This could be coupled with a string describing the primary study investigator(s).</code> <code>PUBLICATION_REQUIRED</code> <code>This data use modifier indicates that requestor agrees to make results of studies using the data available to the larger scientific community.</code> <code>NOT_FOR_PROFIT_NON_COMMERCIAL_USE_ONLY</code> <code>This data use modifier indicates that use of the data is limited to not-for-profit organizations and not-for-profit use, non-commercial use.</code> <code>NON_COMMERCIAL_USE_ONLY</code> <code>This data use modifier indicates that use of the data is limited to not-for-profit use. This indicates that data can be used by commercial organisations for research purposes, but not commercial purposes.</code> <code>NOT_FOR_PROFIT_ORGANISATION_USE_ONLY</code> <code>This data use modifier indicates that use of the data is limited to not-for-profit organizations.</code> <code>GENETIC_STUDIES_ONLY</code> <code>This data use modifier indicates that use is limited to genetic studies only (i.e., studies that include genotype research alone or both genotype and phenotype research, but not phenotype research exclusively).</code> <code>NO_GENERAL_METHODS_RESEARCH</code> <code>This data use modifier indicates that use does not allow methods development research (e.g., development of software or algorithms).</code> <code>RESEARCH_SPECIFIC_RESTRICTIONS</code> <code>This data use modifier indicates that use is limited to studies of a certain research type.</code> <code>POPULATION_ORIGINS_OR_ANCESTRY_RESEARCH_PROHIBITED</code> <code>This data use modifier indicates use for purposes of population, origin, or ancestry research is prohibited.</code>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#data_use_modifier_ids","title":"data_use_modifier_ids","text":"<p>description : The DUO IDs corresponding to the Data Use Modifier terms (e.g., DUO:0000043). required : False data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#data_access_committee","title":"data_access_committee","text":"<p>description : The Data Access Committee linked to this Data Use Policy. required : True data type : DataAccessCommittee </p>"},{"location":"metadata/data_dictionary/DataAccessPolicy/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Dataset/","title":"Dataset","text":""},{"location":"metadata/data_dictionary/Dataset/#description","title":"Description","text":"<p>A Dataset is a collection of Files that is prepared for distribution and is tied to a Data Access Policy.</p>"},{"location":"metadata/data_dictionary/Dataset/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Dataset/#title","title":"title","text":"<p>description : A title for this Dataset. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Dataset/#description_1","title":"description","text":"<p>description : A description summarizing this Dataset. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Dataset/#types","title":"types","text":"<p>description : The type of this Dataset. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Dataset/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Dataset/#data_access_policy","title":"data_access_policy","text":"<p>description : The Data Access Policy that applies to this Dataset. required : True data type : DataAccessPolicy </p>"},{"location":"metadata/data_dictionary/Dataset/#study","title":"study","text":"<p>description : The Study associated with this Dataset. required : True data type : Study </p>"},{"location":"metadata/data_dictionary/Dataset/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Experiment/","title":"Experiment","text":""},{"location":"metadata/data_dictionary/Experiment/#description","title":"Description","text":"<p>An Experiment is an investigation that consists of a coordinated set of actions and observations designed to generate data with the goal of verifying, falsifying, or establishing the validity of a hypothesis.</p>"},{"location":"metadata/data_dictionary/Experiment/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Experiment/#experiment_method","title":"experiment_method","text":"<p>description : The alias of one or more Experiment Methods that are associated with this Experiment. required : True data type : ExperimentMethod </p>"},{"location":"metadata/data_dictionary/Experiment/#title","title":"title","text":"<p>description : The title for this Experiment (e.g., GHGAE_PBMC_RNAseq). required : True data type : string </p>"},{"location":"metadata/data_dictionary/Experiment/#description_1","title":"description","text":"<p>description : A detailed description of this Experiment. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Experiment/#type","title":"type","text":"<p>description : The type of this Experiment. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Experiment/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession of the 'Run' entity (EGAR). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Experiment/#sample","title":"sample","text":"<p>description : The alias of one or more Samples that are associated with this Experiment. required : True data type : Sample </p>"},{"location":"metadata/data_dictionary/Experiment/#attributes","title":"attributes","text":"<p>description : Key/value pairs corresponding to an entity. required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/Experiment/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/","title":"ExperimentMethod","text":""},{"location":"metadata/data_dictionary/ExperimentMethod/#description","title":"Description","text":"<p>The Experiment Method captures technical metadata describing the parameters used to generate output from the Sample.</p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/ExperimentMethod/#name","title":"name","text":"<p>description : A short name identifying this Experiment Method. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#description_1","title":"description","text":"<p>description : A short description of this Experiment Method. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#type","title":"type","text":"<p>description : The type associated with this Experiment Method. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#library_type","title":"library_type","text":"<p>description : Describe the level of omics analysis (e.g., WGS, ATAC). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>WGS</code> <code>Whole genome sequencing library</code> <code>WXS</code> <code>Whole exome sequencing library</code> <code>WCS</code> <code>Whole chromosome sequencing library</code> <code>TOTAL_RNA</code> <code>Total RNA sequencing library</code> <code>M_RNA</code> <code>mRNA sequencing library</code> <code>MI_RNA</code> <code>miRNA sequencing library</code> <code>NC_RNA</code> <code>ncRNA sequencing library</code> <code>ATAC</code> <code>ATAC sequencing library</code> <code>METHYLATION</code> <code>Methylation library</code> <code>CHROMOSOME_CONFORMATION_CAPTURE</code> <code>Chromosome conformation capture library</code> <code>CHIP_SEQ</code> <code>A combination of chromatin immunoprecipitation with DNA sequencing.</code> <code>OTHER</code> <code>A library type not captured by the above vocabulary.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#library_selection_methods","title":"library_selection_methods","text":"<p>description : One or more methods used to select for or against, enrich, or screen the material being sequenced (e.g., random, PCA, cDNA). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>5_METHYLCYTIDINE_ANTIBODY_METHOD</code> <code>Selection of methylated DNA fragments using an antibody raised against 5-methylcytosine or 5-methylcytidine (m5C).</code> <code>CAGE_METHOD</code> <code>Cap-analysis gene expression.</code> <code>C_DNA_METHOD</code> <code>PolyA selection or enrichment for messenger RNA (mRNA). complementary DNA.</code> <code>CF_H_METHOD</code> <code>Cot-filtered highly repetitive genomic DNA.</code> <code>CF_M_METHOD</code> <code>Cot-filtered moderately repetitive genomic DNA.</code> <code>CF_S_METHOD</code> <code>Cot-filtered single/low-copy genomic DNA.</code> <code>CF_T_METHOD</code> <code>Cot-filtered theoretical single-copy genomic DNA.</code> <code>CHIP_SEQ_METHOD</code> <code>Chromatin immunoprecipitation.</code> <code>D_NASE_METHOD</code> <code>Deoxyribonuclease (MNase) digestion.</code> <code>HMPR_METHOD</code> <code>Hypo-methylated partial restriction digest.</code> <code>HYBRID_SELECTION_METHOD</code> <code>Selection by hybridization in array or solution.</code> <code>MBD2_PROTEIN_METHYL_CP_G_BINDING_DOMAIN_METHOD</code> <code>Enrichment by methyl-CpG binding domain.</code> <code>MF_METHOD</code> <code>Methyl Filtrated</code> <code>M_NASE_METHOD</code> <code>Micrococcal Nuclease (MNase) digestion.</code> <code>MSLL_METHOD</code> <code>Methylation Spanning Linking Library.</code> <code>PCR_METHOD</code> <code>Source material was selected by designed primers.</code> <code>RACE_METHOD</code> <code>Rapid Amplification of cDNA Ends.</code> <code>RANDOM_PCR_METHOD</code> <code>Source material was selected by randomly generated primers.</code> <code>RANDOM_METHOD</code> <code>Random selection by shearing or other method.</code> <code>RT_PCR_METHOD</code> <code>Source material was selected by reverse transcription PCR.</code> <code>REDUCED_REPRESENTATION_METHOD</code> <code>Reproducible genomic subsets, often generated by restriction fragment size selection, containing a manageable number of loci to facilitate re-sampling.</code> <code>RESTRICTION_DIGEST_METHOD</code> <code>DNA fractionation using restriction enzymes.</code> <code>SIZE_FRACTIONATION_METHOD</code> <code>Physical selection of size appropriate targets.</code> <code>UNSPECIFIED</code> <code>The library selection cannot be specified.</code> <code>OTHER</code> <code>Other library enrichment, screening, or selection process.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#library_preparation","title":"library_preparation","text":"<p>description : The general method for preparation of the sequencing library (e.g., KAPA PCR-free). required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#library_preparation_kit_retail_name","title":"library_preparation_kit_retail_name","text":"<p>description : The retail name for the kit used to construct a genomic library. This may include the vendor name, kit name and kit version (e.g., Agilent sure select Human Exome V8, Twist RefSeq Exome). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>10X_GENOMICS_CHROMIUM_SINGLE_CELL_3_V2</code> <code>10X Genomics Chromium Single Cell 3' v2 Reagent Kit</code> <code>10X_GENOMICS_CHROMIUM_SINGLE_CELL_3_V3</code> <code>10X Genomics Chromium Single Cell 3' v3 Reagent Kit</code> <code>ACCEL_NGS_2_S_PLUS_DNA_LIBRARY_KIT</code> <code>Accel-NGS 2S Plus DNA Library Kit</code> <code>ACCEL_NGS_METHYL_SEQ_DNA</code> <code>Accel-NGS Methyl-Seq DNA Library Kit</code> <code>AGILENT_STRAND_SPECIFIC_RNA</code> <code>Agilent SureSelect Strand Specific RNA Library Preparation Kit</code> <code>AGILENT_SURE_SELECT_CUSTOM_ENRICHMENT_KIT</code> <code>Agilent SureSelect Target Enrichment System</code> <code>AGILENT_SURE_SELECT_V3</code> <code>Agilent SureSelect Human All Exon V3</code> <code>AGILENT_SURE_SELECT_V4</code> <code>Agilent SureSelect Human All Exon V4</code> <code>AGILENT_SURE_SELECT_V4_UTRS</code> <code>Agilent SureSelect Human All Exon V4 + UTRs</code> <code>AGILENT_SURE_SELECT_V5</code> <code>Agilent SureSelect Human All Exon V5</code> <code>AGILENT_SURE_SELECT_V5_UTRS</code> <code>Agilent SureSelect Human All Exon V5 + UTRs</code> <code>AGILENT_SURE_SELECT_V6</code> <code>Agilent SureSelect Human All Exon V6</code> <code>AGILENT_SURE_SELECT_V6_UTRS</code> <code>Agilent SureSelect Human All Exon V6 + UTRs</code> <code>AGILENT_SURE_SELECT_V6_PLUS_ONE</code> <code>Agilent SureSelect XT Human All Exon V6 Plus 1</code> <code>AGILENT_SURE_SELECT_V6_PLUS_TWO</code> <code>Agilent SureSelect XT Human All Exon V6 Plus 2</code> <code>AGILENT_SURE_SELECT_V8</code> <code>Agilent SureSelect XT HS Human All Exon V8</code> <code>AGILENT_SURE_SELECT_V8_UTRS</code> <code>Agilent SureSelect XT HS Human All Exon V8 + UTRs</code> <code>AGILENT_SURE_SELECT_V8_NCV</code> <code>Agilent SureSelect XT HS Human All Exon V8 + NCV</code> <code>AGILENT_SURE_SELECT_QXT_WGS</code> <code>Agilent SureSelectQXT Library Prep for WGS</code> <code>AGILENT_SURE_SELECT_XT_HS_HUMAN_ALL_EXON_V7</code> <code>Agilent SureSelect CT HS and Low Input Human All Exon V7</code> <code>AGILENT_SURE_SELECT_XT_HS_HUMAN_ALL_EXON_V7_ONE</code> <code>Agilent SureSelect CT HS and Low Input Human All Exon V7 Plus 1</code> <code>AGILENT_SURE_SELECT_XT_HS_HUMAN_ALL_EXON_V7_TWO</code> <code>Agilent SureSelect CT HS and Low Input Human All Exon V7 Plus 2</code> <code>AGILENT_SURE_SELECT_CLINICAL_RESEARCH_EXOME_V2</code> <code>Agilent SureSelect XT Clinical Research Exome V2</code> <code>AGILENT_SURE_SELECT_CLINICAL_RESEARCH_EXOME_V2_ONE</code> <code>Agilent SureSelect XT Clinical Research Exome V2 Plus 1</code> <code>AGILENT_SURE_SELECT_CLINICAL_RESEARCH_EXOME_V2_TWO</code> <code>Agilent SureSelect XT Clinical Research Exome V2 Plus 2</code> <code>AGILENT_CLEAR_SEQ_COMPREHENSIVE_CANCER_XT</code> <code>Agilent ClearSeq Comprehensive Cancer XT</code> <code>AGILENT_SURE_SELECT_CUSTOM_TIER1</code> <code>Agilent SureSelect Custom Tier1</code> <code>AGILENT_SURE_SELECT_CUSTOM_TIER2</code> <code>Agilent SureSelect Custom Tier2</code> <code>AGILENT_SURE_SELECT_CUSTOM_TIER3</code> <code>Agilent SureSelect Custom Tier3</code> <code>AGILENT_SURE_SELECT_CUSTOM_TIER4</code> <code>Agilent SureSelect Custom Tier4</code> <code>AGILENT_SURE_SELECT_CUSTOM_TIER5</code> <code>Agilent SureSelect Custom Tier5</code> <code>AVENIO_CT_DNA_TARGETED_KIT</code> <code>AVENIO ctDNA Targeted Kit V2</code> <code>AVENIO_CT_DNA_SURVEILLANCE_KIT</code> <code>AVENIO ctDNA Surveillance Kit V2</code> <code>AVENIO_CT_DNA_EXPANDED_KIT</code> <code>AVENIO ctDNA Expanded Kit V2</code> <code>IDT_X_GEN_EXOME_RESEARCH_PANEL</code> <code>IDT xGen Exome Research Panel V2</code> <code>ILLUMINA_DNA_PCR_FREE_PREP</code> <code>Illumina DNA PCR-Free Prep</code> <code>ILLUMINA_NEXTERA_DNA_FLEX</code> <code>Illumina Nextera DNA Flex</code> <code>ILLUMINA_DNA_PREP</code> <code>Illumina DNA Prep</code> <code>ILLUMINA_NEXTERA_EXOME_ENRICHMENT_KIT</code> <code>Illumina Nextera Exome Enrichment Kit</code> <code>ILLUMINA_DNA_PREP_WITH_ENRICHMENT</code> <code>Illumina DNA Prep with Enrichment</code> <code>ILLUMINA_DNA_PREP_WITH_EXOME_2_5_ENRICHMENT</code> <code>Illumina DNA Prep with Exome 2.5 Enrichment</code> <code>ILLUMINA_STRANDED_M_RNA_PREP</code> <code>Illumina Stranded mRNA Prep</code> <code>ILLUMINA_NEXTERA_DNA_LIBRARY_PREPARATION_KIT</code> <code>Illumina Nextera DNA Library Preparation Kit</code> <code>ILLUMINA_NEXTERA_XT_DNA_LIBRARY_PREPARATION_KIT</code> <code>Illumina Nextera XT DNA Library Preparation Kit</code> <code>ILLUMINA_RNA_PREP_WITH_ENRICHMENT</code> <code>Illumina RNA Prep with Enrichment</code> <code>ILLUMINA_TRU_SEQ_CH_IP_LIBRARY_PREPARATION_KIT</code> <code>TruSeq ChIP Library Preparation Kit</code> <code>ILLUMINA_TRU_SEQ_CUSTOM_AMPLICON_LOW_INPUT_KIT</code> <code>Illumina TruSeq Custom Amplicon Low Input Kit</code> <code>ILLUMINA_TRU_SEQ_CUSTOM_AMPLICON_V_1_5</code> <code>Illumina TruSeq Custom Amplicon v1.5</code> <code>ILLUMINA_TRU_SEQ_DNA_EXOME</code> <code>Illumina TruSeq DNA Exome</code> <code>ILLUMINA_TRU_SEQ_DNA_NANO</code> <code>Illumina TruSeq DNA Nano</code> <code>ILLUMINA_TRU_SEQ_DNA_NANO_LIBRARY_PREP_KIT_FOR_NEO_PREP</code> <code>Illumina TruSeq DNA Nano Library Prep Kit for NeoPrep</code> <code>ILLUMINA_TRU_SEQ_NANO_DNA_HT</code> <code>Illumina TruSeq Nano DNA High Throughput</code> <code>ILLUMINA_TRU_SEQ_NANO_DNA_LT</code> <code>Illumina TruSeq Nano DNA Low Throughput</code> <code>ILLUMINA_TRU_SEQ_FFPE_DNA_LIBRARY_PREP_QC_KIT</code> <code>TruSeq FFPE DNA Library Prep QC Kit</code> <code>ILLUMINA_TRU_SEQ_DNA_PCR_FREE</code> <code>Illumina TruSeq DNA PCR-Free</code> <code>ILLUMINA_TRU_SEQ_RNA_LIBRARY_PREP_KIT_V2</code> <code>Illumina TruSeq RNA Library Prep Kit v2</code> <code>ILLUMINA_TRU_SEQ_RNA_EXOME</code> <code>Illumina TruSeq RNA Exome</code> <code>ILLUMINA_TRU_SEQ_SMALL_RNA_LIBRARY_PREPARATION_KIT</code> <code>Illumina TruSeq Small RNA Library Preparation Kit</code> <code>ILLUMINA_TRU_SEQ_STRANDED_TOTAL_RNA</code> <code>Illumina TruSeq Stranded Total RNA</code> <code>ILLUMINA_TRU_SEQ_STRANDED_M_RNA</code> <code>Illumina TruSeq Stranded mRNA</code> <code>ILLUMINA_TRU_SEQ_STRANDED_TOTAL_RNA_WITH_RIBO_ZERO_GOLD</code> <code>Illumina TruSeq Stranded Total RNA with Ribo-Zero Globin</code> <code>VAHTS_TOTAL_RNA_SEQ_H_M_R_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>VAHTS Total RNA (H/M/R) Library Prep Kit for Illumina</code> <code>ILLUMINA_NEXTERA_XT_DNA</code> <code>Illumina Nextera XT DNA Library Preparation Kit</code> <code>ILLUMINA_TRU_SEQ_TARGETED_RNA_EXPRESSION_STEM_CELL_PANEL</code> <code>Illumina TruSeq Targeted RNA Expression Stem Cell Panel</code> <code>ILLUMINA_TRU_SEQ_TARGETED_RNA_EXPRESSION_P_53_PANEL</code> <code>Illumina TruSeq Targeted RNA Expression p53 Panel</code> <code>ILLUMINA_TRU_SIGHT_ONCOLOGY_500</code> <code>Illumina TruSight Oncology 500</code> <code>ILLUMINA_TRU_SIGHT_ONCOLOGY_500_HIGH_THROUGHPUT</code> <code>Illumina TruSight Oncology High Throughput</code> <code>ILLUMINA_TRU_SIGHT_ONCOLOGY_500_CT_DNA</code> <code>Illumina TruSight Oncology 500 ctDNA</code> <code>ILLUMINA_TRU_SIGHT_RNA_FUSION_PANEL</code> <code>Illumina TruSight RNA Fusion Panel</code> <code>ILLUMINA_TRU_SIGHT_RNA_PAN_CANCER</code> <code>Illumina TruSight RNA Pan-Cancer</code> <code>ILLUMINA_TRU_SIGHT_TUMOR_15</code> <code>Illumina TruSight Tumor 15</code> <code>ILLUMINA_TRU_SIGHT_TUMOR_170</code> <code>Illumina TruSight Tumor 170</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_BRCA_PANEL</code> <code>Illumina AmpliSeq for Illumina BRCA Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_CANCER_HOTSPOT_PANEL_V2</code> <code>Illumina AmpliSeq for Illumina Cancer Hotspot Panel v2</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_CHILDHOOD_CANCER_PANEL</code> <code>Illumina AmpliSeq for Illumina Childhood Cancer Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_COMPREHENSIVE_PANEL_V3</code> <code>Illumina AmpliSeq for Illumina Comprehensive Panel v3</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_CUSTOM_DNA_PANEL</code> <code>Illumina AmpliSeq for Illumina Custom DNA Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_CUSTOM_RNA_FUSION_PANEL</code> <code>Illumina AmpliSeq for Illumina Custom RNA Fusion Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_CUSTOM_RNA_PANEL</code> <code>Illumina AmpliSeq for Illumina Custom RNA Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_FOCUS_PANEL</code> <code>Illumina AmpliSeq for Illumina Focus Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_IMMUNE_REPERTOIRE_PLUS_TCR_BETA_PANEL</code> <code>Illumina AmpliSeq for Illumina Immune Repertoire Plus, TCR beta Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_IMMUNE_RESPONSE_PANEL</code> <code>Illumina AmpliSeq for Illumina Immune Response Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_LIBRARY_PREP_INDEXES_AND_ACCESSOIRES</code> <code>Illumina AmpliSeq for Illumina Library Prep, Indexes, and Accessoires</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_MYELOID_PANEL</code> <code>Illumina AmpliSeq for Illumina Myeloid Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_ON_DEMAND</code> <code>Illumina AmpliSeq for Illumina On-Demand</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_TCR_BETA_SR_PANEL</code> <code>Illumina AmpliSeq for Illumina TCR beta-SR Panel</code> <code>ILLUMINA_AMPLI_SEQ_FOR_ILLUMINA_TRANSCRIPTOME_HUMAN_GENE_EXPRESSION_PANEL</code> <code>Illumina AmpliSeq for Illumina Transcriptome Human Gene Expression Panel</code> <code>ILLUMINA_COMPLETE_LONG_READ_PREP_HUMAN</code> <code>Illumina Complete Long Read Prep, Human</code> <code>INFORM_ONCO_PANEL_HG19</code> <code>Inform Onco Panel Hg19</code> <code>ION_AMPLI_SEQ_EXOME_KIT</code> <code>Ion AmpliSeq Exome RDY Kit</code> <code>KAPA_HIFI_HOT_START_READYMIX</code> <code>KAPA HiFi HotStart ReadyMix Kit</code> <code>KAPA_HYPER_PREP_KIT</code> <code>KAPA HyperPrep Kit</code> <code>KAPA_HYPER_PREP_PCR_FREE_KIT</code> <code>KAPA HyperPrep Kit (PCR-free)</code> <code>KAPA_HYPER_PLUS_KIT</code> <code>KAPA HyperPlus Kit</code> <code>KAPA_M_RNA_HYPER_PREP_KIT</code> <code>KAPA RNA HyperPrep Kit</code> <code>NEB_NEXT_GLOBIN_R_RNA_DEPLETION_HU_MO_RAT_RNA_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Globin &amp; rRNA Depletion Kit (Human/Mouse/Rat) with RNA Sample Purification Beads</code> <code>NEB_NEXT_GLOBIN_R_RNA_DEPLETION_KIT_HUMAN_MOUSE_RAT</code> <code>NEBNext Globin &amp; rRNA Depletion Kit (Human/Mouse/Rat)</code> <code>NEB_NEXT_GLOBIN_R_RNA_DEPLET_V2_HU_MO_RAT_RNA_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Globin &amp; rRNA Depletion Kit v2 (Human/Mouse/Rat) with RNA Sample Purification Beads</code> <code>NEB_NEXT_GLOBIN_R_RNA_DEPLETION_KIT_V2_HUMAN_MOUSE_RAT</code> <code>NEBNext Globin &amp; rRNA Depletion Kit v2 (Human/Mouse/Rat)</code> <code>NEB_NEXT_RNA_DEPLETION_CORE_REAGENT_SET</code> <code>NEBNext RNA Depletion Core Reagent Set</code> <code>NEB_NEXT_RNA_DEPLETION_CORE_REAGENT_SET_RNA_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext RNA Depletion Core Reagent Set with RNA Sample Purification Beads</code> <code>NEB_NEXT_POLY_A_M_RNA_MAGNETIC_ISOLATION_MODULE</code> <code>NEBNext Poly(A) mRNA Magnetic Isolation Module</code> <code>NEB_NEXT_SINGLE_CELL_LOW_INPUT_CDNA_SYNTHESIS_AND_AMPLIFICATION_MODULE</code> <code>NEBNext Single Cell / Low Input cDNA Synthesis and Amplification Module</code> <code>NEB_NEXT_SINGLE_CELL_LOW_INPUT_RNA_LIBRARY_KIT_FOR_ILLUMINA</code> <code>NEBNext Single Cell / Low Input RNA Library Kit for Illumina</code> <code>NEB_NEXT_RNA_ULTRA_II_FIRST_STRAND_SYNTHESIS_MODULE</code> <code>NEBNext Ultra II RNA First Strand Synthesis Module</code> <code>NEB_NEXT_RNA_ULTRA_II_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II RNA Library Prep Kit for Illumina</code> <code>NEB_NEXT_RNA_ULTRA_II_LIBRARY_PREP_WITH_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II RNA Library Prep with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_DIRECTIONAL_RNA_SAMPLE_WITH_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II Directional RNA Library Prep with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_DIRECTIONAL_RNA_SECOND_STRAND_SYNTHESIS_MODULE</code> <code>NEBNext Ultra II Directional RNA Second Strand Synthesis Module</code> <code>NEB_NEXT_ULTRA_DNA</code> <code>NEBNext Ultra DNA Library Prep for Illumina</code> <code>NEB_NEXT_ULTRA_II_DNA_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II DNA Library Prep Kit for Illumina</code> <code>NEB_NEXT_ULTRA_II_DNA_ILLUMINA_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II DNA Library Prep for Illumina with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_DIRECTIONAL_RNA_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II Directional RNA Library Prep Kit for Illumina</code> <code>NEB_NEXT_ULTRA_II_FS_DNA_MODULE</code> <code>NEBNext Ultra II FS DNA Module</code> <code>NEB_NEXT_ULTRA_II_END_REPAIR_DA_TAILING_MODULE</code> <code>NEBNext Ultra II End Repair/dA-Tailing Module</code> <code>NEB_NEXT_ULTRA_II_FS_DNA_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II FS DNA Library Prep Kit for Illumina</code> <code>NEB_NEXT_ULTRA_II_FS_DNA_ILLUMINA_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II FS DNA Library Prep for Illumina with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_DNA_PCR_FREE_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II DNA PCR-free Library Prep with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_FS_DNA_PCR_FREE_SAMPLE_PURIFICATION_BEADS</code> <code>NEBNext Ultra II FS DNA PCR-free Library Prep with Sample Purification Beads</code> <code>NEB_NEXT_ULTRA_II_DNA_PCR_FREE_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II DNA PCR-free Library Prep Kit for Illumina</code> <code>NEB_NEXT_ULTRA_II_FS_DNA_PCR_FREE_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Ultra II FS DNA PCR-free Library Prep Kit for Illumina</code> <code>NEB_NEXT_ULTRA_II_LIGATION_MODULE</code> <code>NEBNext Ultra II Ligation Module</code> <code>NEB_NEXT_ULTRA_II_Q5_MASTER_MIX</code> <code>NEBNext Ultra II Q5 Master Mix</code> <code>NEB_NEXT_Q5_HOT_START_HIFI_PCR_MASTER_MIX</code> <code>NEBNext Q5 Hot Start HiFi PCR Master Mix</code> <code>NEB_TEMPLATE_SWITCHING_RT_ENZYME_MIX</code> <code>NEB Template Switching RT Enzyme Mix</code> <code>NEB_NEXT_LIBRARY_PCR_MASTER_MIX</code> <code>NEBNext Library PCR Master Mix</code> <code>NEB_NEXT_ULTRA_SHEAR</code> <code>NEBNext UltraShear</code> <code>NEB_NEXT_ULTRA_SHEAR_FFPE_DNA_LIBRARY_PREP_KIT</code> <code>NEBNext UltraShear FFPE DNA Library Prep Kit</code> <code>NEB_NEXT_COMPANION_MODULE_ONT_LIGATION_SEQUENCING</code> <code>NEBNext Companion Module for Oxford Nanopore Technologies Ligation Sequencing</code> <code>NEB_NEXT_FAST_DNA_FRAGMENTATION_AND_LIBRARY_PREP_SET_FOR_ION_TORRENT</code> <code>NEBNext Fast DNA Fragmentation and Library Prep Set for Ion Torrent</code> <code>NEB_NEXT_FAST_DNA_LIBRARY_PREP_SET_FOR_ION_TORRENT</code> <code>NEBNext Fast DNA Library Prep Set for Ion Torrent</code> <code>NEB_NEXT_FFPE_DNA_LIBRARY_PREP_KIT</code> <code>NEBNext FFPE DNA Library Prep Kit</code> <code>NEB_NEXT_FFPE_DNA_REPAIR_MIX</code> <code>NEBNext FFPE DNA Repair Mix</code> <code>NEB_NEXT_FFPE_DNA_REPAIR_V2_MODULE</code> <code>NEBNext FFPE DNA Repair v2 Module</code> <code>NEB_NEXT_DS_DNA_FRAGMENTASE</code> <code>NEBNext dsDNA Fragmentase</code> <code>NEB_NEXT_MAGNETIC_SEPARATION_RACK</code> <code>NEBNext Magnetic Separation Rack</code> <code>NEB_NEXT_LIBRARY_QUANT_FOR_ILLUMINA</code> <code>NEBNext Library Quant for Illumina</code> <code>NEB_NEXT_LIBRARY_QUANT_DNA_STANDARDS</code> <code>NEBNext Library Quant DNA Standards</code> <code>NEB_NEXT_MAGNESIUM_RNA_FRAGMENTATION_MODULE</code> <code>NEBNext Magnesium RNA Fragmentation Module</code> <code>NEB_NEXT_DIRECT_GENOTYPING_SOLUTION</code> <code>NEBNext Direct Genotyping Solution</code> <code>NEB_NEXT_ENZYMATIC_METHYL_SEQ_CONVERSION_MODULE</code> <code>NEBNext Enzymatic Methyl-seq Conversion Module</code> <code>NEB_NEXT_ENZYMATIC_METHYL_SEQ_KIT</code> <code>NEBNext Enzymatic Methyl-seq Kit</code> <code>NEB_NEXT_MULTIPLEX_SMALL_RNA_LIBRARY_PREP_KIT_FOR_ILLUMINA</code> <code>NEBNext Multiplex Small RNA Library Prep Kit for Illumina</code> <code>NEB_NEXT_SMALL_RNA_LIBRARY_PREP_SET_FOR_ILLUMINA_MULTIPLEX_COMPATIBLE</code> <code>NEBNext Small RNA Library Prep Set for Illumina (Multiplex Compatible)</code> <code>EPI_MARK_5_HMC_AND_5_MC_ANALYSIS_KIT</code> <code>EpiMark 5-hmC and 5-mC Analysis Kit</code> <code>EPI_MARK_METHYLATED_DNA_ENRICHMENT_KIT</code> <code>EpiMark Methylated DNA Enrichment Kit</code> <code>EPI_MARK_N6_METHYLADENOSINE_ENRICHMENT_KIT</code> <code>EpiMark N6-Methyladenosine Enrichment Kit</code> <code>EPI_MARK_NUCLEOSOME_ASSEMBLY_KIT</code> <code>EpiMark Nucleosome Assembly Kit</code> <code>EPI_MARK_HOT_START_TAG_DNA_POLYMERASE</code> <code>EpiMark Hot Start Tag DNA Polymerase</code> <code>PICO_METHYL_SEQ</code> <code>Pico Methyl-Seq Library Prep Kit</code> <code>TAKARA_SMART_SEQ_V4_ULTRA_LOW_INPUT_RNA_KIT</code> <code>Takara SMART-Seq v4 Ultra Low Input RNA Kit</code> <code>TAKARA_SMART_ER_STRANDED_TOTAL_RNA_SEQ_KIT</code> <code>Takara SMARTer Stranded RNA-Seq Kit</code> <code>TAKARA_SMART_ER_ULTRA_LOW_INPUT_RNA_KIT</code> <code>Takara SMARTer Universal Low Input RNA Kit</code> <code>TAKARA_SMART_SEQ2_TAG</code> <code>Takara Smart-Seq2 library preparation</code> <code>TAKARA_SMART_ER_PREP_X_DNA_LIBRARY_KIT</code> <code>Takara SMARTer PrepX DNA Library Kit</code> <code>SUPER_SCRIPT_II_RT_BULK</code> <code>SuperScript II Reverse Transkriptase</code> <code>SURE_CELL_ATAC_SEQ_LIBRARY_PREP_KIT</code> <code>SureCell ATAC-Seq Library Prep Kit</code> <code>EUROFINS_ENRICHMENT_CUSTOM</code> <code>Eurofins Genomics Custom Enrichment Kit</code> <code>TWIST_HUMAN_CORE_EXOME_KIT</code> <code>Twist Human Core Exome Kit</code> <code>TWIST_HUMAN_CORE_EXOME_PLUS_KIT</code> <code>Twist Human Core Exome Plus Kit</code> <code>ULTRALOW_METHYL_SEQ_WITH_TRUE_METHYL_OX_BS</code> <code>TECAN Ultralow Methyl-Seq with TrueMethyl oxBS</code> <code>OTHER</code> <code>A Library Preparation Kit not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#library_preparation_kit_manufacturer","title":"library_preparation_kit_manufacturer","text":"<p>description : The manufacturer of the kit used for library preparation. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#primer","title":"primer","text":"<p>description : The type of primer used for reverse transcription (e.g., oligo-dT or random). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>OLIGO_D_T</code> <code>An oligonucleotide primer consisting of thymidine bases only. It is used to target messenger RNA molecules with poly-adenosine 3' end.</code> <code>RANDOM</code> <code>An oligonucleotide primer with random sequence.</code> <code>GENE_SPECIFIC</code> <code>Ready-to-use, usually commercially prepared primers that are used to detect specific genes.</code> <code>OTHER</code> <code>A primer not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#end_bias","title":"end_bias","text":"<p>description : The end of the cDNA molecule that is preferentially sequenced (e.g., \u2157 prime end, full-length). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>3_PRIME_END</code> <code>The sequencing method preferentially captures the nucleic acids towards the 3 prime end of the targeted molecule.</code> <code>5_PRIME_END</code> <code>The sequencing method preferentially captures the nucleic acids towards the 5 prime end of the targeted molecule.</code> <code>FULL_LENGTH</code> <code>Captures the full length of the targeted molecule.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#target_regions","title":"target_regions","text":"<p>description : Subset of genes or specific regions of the genome, which are most likely to be involved in the phenotype under study. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#rnaseq_strandedness","title":"rnaseq_strandedness","text":"<p>description : The strandedness of the library, whether reads come from both strands of the cDNA or only from the first (antisense) or the second (sense) strand. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>SENSE</code> <code>Having a DNA sequence identical to that of a messenger RNA molecule; the coding strand in double-stranded DNA.</code> <code>ANTISENSE</code> <code>Having a DNA sequence complementary to that of a messenger RNA molecule; the non-coding strand in double-stranded DNA.</code> <code>UNSTRANDED</code> <code>Non-directional sequencing, where the reads can map from either the transcript strand or its complement.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#instrument_model","title":"instrument_model","text":"<p>description : The name and model of the technology platform used to perform sequencing. required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>454_GS</code> <code>454 GS</code> <code>454_GS_20</code> <code>454 GS 20</code> <code>454_GS_FLX</code> <code>454 GS FLX</code> <code>454_GS_FLX_TITANIUM</code> <code>454 FS FLX Titanium</code> <code>454_GS_FLX+</code> <code>454 GS FLX+</code> <code>454_GS_JUNIOR</code> <code>454 GS Junior</code> <code>AB_310_GENETIC_ANALYZER</code> <code>AB 310 Genetic Analyzer</code> <code>AB_3130_GENETIC_ANALYZER</code> <code>AB 3130 Genetic Analyzer</code> <code>AB_3130XL_GENETIC_ANALYZER</code> <code>AB 3130XL Genetic Analyzer</code> <code>AB_3500_GENETIC_ANALYZER</code> <code>AB 3500 Genetic Analyzer</code> <code>AB_3500XL_GENETIC_ANALYZER</code> <code>AB 3500XL Genetic Analyzer</code> <code>AB_3730_GENETIC_ANALYZER</code> <code>AB 3730 Genetic Analyzer</code> <code>AB_3730XL_GENETIC_ANALYZER</code> <code>AB 3730XL Genetic Analyzer</code> <code>AB_5500_GENETIC_ANALYZER</code> <code>AB 5500 Genetic Analyzer</code> <code>AB_5500XL_GENETIC_ANALYZER</code> <code>AB 5500XL Genetic Analyzer</code> <code>AB_5500XL-W_GENETIC_ANALYSIS_SYSTEM</code> <code>AB 5500 XL-W Genetic Analysis System</code> <code>BGISEQ-50</code> <code>BGISEQ-50:</code> <code>BGISEQ-500</code> <code>BGISEQ-500</code> <code>DNBSEQ-G400</code> <code>DNBSEQ-G400</code> <code>DNBSEQ-G400_FAST</code> <code>DNBSEQ-G400_FAST</code> <code>DNBSEQ-G50</code> <code>DNBSEQ-G50</code> <code>DNBSEQ-T7</code> <code>DNBSEQ-T7</code> <code>ELEMENT_AVITI</code> <code>Element AVITI</code> <code>GRIDION</code> <code>GridION</code> <code>HELICOS_HELISCOPE</code> <code>Helicos HeliScope</code> <code>HISEQ_X_FIVE</code> <code>HiSeq X Five</code> <code>HISEQ_X_TEN</code> <code>HiSeq X Ten</code> <code>ILLUMINA_GENOME_ANALYZER</code> <code>Illumina Genome Analyzer</code> <code>ILLUMINA_GENOME_ANALYZER_II</code> <code>Illumina Genome Analyzer II</code> <code>ILLUMINA_GENOME_ANALYZER_IIX</code> <code>Illumina Genome Analyzer IIx</code> <code>ILLUMINA_HISCANSQ</code> <code>Illumina HiScanSQ</code> <code>ILLUMINA_HISEQ_1000</code> <code>Illumina HiSeq 1000</code> <code>ILLUMINA_HISEQ_1500</code> <code>Illumina HiSeq 1500</code> <code>ILLUMINA_HISEQ_2000</code> <code>Illumina HiSeq 2000</code> <code>ILLUMINA_HISEQ_2500</code> <code>Illumina HiSeq 2500</code> <code>ILLUMINA_HISEQ_3000</code> <code>Illumina HiSeq 3000</code> <code>ILLUMINA_HISEQ_4000</code> <code>Illumina HiSeq 4000</code> <code>ILLUMINA_HISEQ_X</code> <code>Illumina HiSeq X</code> <code>ILLUMINA_MISEQ</code> <code>Illumina MiSeq</code> <code>ILLUMINA_MINISEQ</code> <code>Illumina MiniSeq</code> <code>ILLUMINA_NOVASEQ_6000</code> <code>Illumina NovaSeq 6000</code> <code>ILLUMINA_NOVASEQ_X</code> <code>Illumina NovaSeq X</code> <code>ILLUMINA_ISEQ_100</code> <code>Illumina iSeq 100</code> <code>ION_GENESTUDIO_S5</code> <code>Ion Genestudio S5</code> <code>ION_GENESTUDIO_S5_PLUS</code> <code>Ion Genestudio S5 Plus</code> <code>ION_GENESTUDIO_S5_PRIME</code> <code>Ion Genestudio S5 Prime</code> <code>ION_TORRENT_GENEXUS</code> <code>Ion Torrent Genexus</code> <code>ION_TORRENT_PGM</code> <code>Ion Torrent PGM</code> <code>ION_TORRENT_PROTON</code> <code>Ion Torrent Proton</code> <code>ION_TORRENT_S5</code> <code>Ion Torrent S5</code> <code>ION_TORRENT_S5_XL</code> <code>Ion Torrent S5 XL</code> <code>MGISEQ-2000RS</code> <code>MGISEQ-2000RS</code> <code>MINION</code> <code>MinION</code> <code>NEXTSEQ_1000</code> <code>NextSeq 1000</code> <code>NEXTSEQ_2000</code> <code>NextSeq 2000</code> <code>NEXTSEQ_500</code> <code>NextSeq 500</code> <code>NEXTSEQ_550</code> <code>NextSeq 550</code> <code>PACBIO_RS</code> <code>PacBio RS</code> <code>PACBIO_RS_II</code> <code>PacBio RS II</code> <code>PROMETHION</code> <code>PromethION</code> <code>SEQUEL</code> <code>Sequel</code> <code>SEQUEL_II</code> <code>Sequel II</code> <code>SEQUEL_IIE</code> <code>Sequel IIe</code> <code>UG_100</code> <code>UG 100</code> <code>UNSPECIFIED</code> <code>Instrument model is unspecified.</code> <code>OTHER</code> <code>Other instrument model than mentioned above.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#sequencing_center","title":"sequencing_center","text":"<p>description : Center where sample was sequenced. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#sequencing_read_length","title":"sequencing_read_length","text":"<p>description : Length of sequencing reads (e.g., long or short or actual number of the read length). required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#sequencing_layout","title":"sequencing_layout","text":"<p>description : Describe whether the library was sequenced in single-end (forward or reverse) or paired-end mode. required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>SE</code> <code>Single end sequencing.</code> <code>PE</code> <code>Paired end sequencing.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#target_coverage","title":"target_coverage","text":"<p>description : Mean coverage for whole genome sequencing, or mean target coverage for whole exome and targeted sequencing, (i.e. the number of times a particular locus was sequenced). required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#flow_cell_id","title":"flow_cell_id","text":"<p>description : Flow cell ID (e.g., Experiment ID_Cell 1_Lane_1). required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#flow_cell_type","title":"flow_cell_type","text":"<p>description : Type of flow cell used (e.g., S4, S2 for NovaSeq; PromethION, Flongle for Nanopore). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>ILLUMINA_NOVA_SEQ_S2</code> <code>Usage of Illumina NovaSeq S2 flow cell.</code> <code>ILLUMINA_NOVA_SEQ_S4</code> <code>Usage of Illumina NovaSeq S4 flow cell.</code> <code>PROMETHION</code> <code>Usage of PromethION flow cell.</code> <code>FLONGLE</code> <code>Usage of Flongle flow cell.</code> <code>MINION</code> <code>Usage of MinION flow cell.</code> <code>GRIDION</code> <code>Usage of GridION flow cell.</code> <code>OTHER</code> <code>Usage of a flow cell not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#sample_barcode_read","title":"sample_barcode_read","text":"<p>description : The type of read that contains the sample barcode (e.g., index1, index2, read1, read2). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>INDEX1</code> <code>Sample barcode read location is in Index 1.</code> <code>INDEX1_AND_INDEX2</code> <code>Sample barcode read location is in Index 1 and Index 2.</code> <code>OTHER</code> <code>Sample barcode read is neither in Index 1 or Index 1 and Index 2.</code>"},{"location":"metadata/data_dictionary/ExperimentMethod/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession of the 'Experiment' entity (EGAX). required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#attributes","title":"attributes","text":"<p>description : One or more attributes that further characterize this Experiment Method. required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/ExperimentMethod/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/","title":"ExperimentMethodSupportingFile","text":""},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#description","title":"Description","text":"<p>An Experiment Method Supporting File is a File that contains additional information relevant for the Experiment Method, such as (unstructured) protocols.</p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#format","title":"format","text":"<p>description : The file format of the Supporting File (e.g., TXT, JSON). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CSV</code> <code>Tabular data represented as comma-separated values in a text file.</code> <code>JSON</code> <code>JavaScript Object Notation format; a lightweight, text-based format to represent tree-structured data using key-value pairs.</code> <code>PED</code> <code>The PED file describes individuals and genetic data and is used by the Plink package.</code> <code>TSV</code> <code>Tabular data represented as tab-separated values in a text file.</code> <code>TXT</code> <code>Textual format. Data in text format can be compressed into binary format, or can be a value of an XML element or attribute. Markup formats are not considered textual (or more precisely, not plain-textual).</code> <code>YAML</code> <code>YAML (YAML Ain't Markup Language) is a human-readable tree-structured data serialisation language.</code> <code>OTHER</code> <code>A file format not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#experiment_method","title":"experiment_method","text":"<p>description : The Experiment Method associated with an entity. required : True data type : ExperimentMethod </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#name","title":"name","text":"<p>description : The given filename. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#dataset","title":"dataset","text":"<p>description : The Dataset alias associated with this File. required : True data type : Dataset </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#included_in_submission","title":"included_in_submission","text":"<p>description : Whether a File is included in the Submission or not. required : True data type : boolean </p>"},{"location":"metadata/data_dictionary/ExperimentMethodSupportingFile/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Individual/","title":"Individual","text":""},{"location":"metadata/data_dictionary/Individual/#description","title":"Description","text":"<p>An Individual is a Person who is participating in a Study.</p>"},{"location":"metadata/data_dictionary/Individual/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Individual/#phenotypic_features_terms","title":"phenotypic_features_terms","text":"<p>description : The phenotypic feature concepts that the entity is associated with at the time of retrieval from the organism. The Phenotypic Feature is captured using a concept from the Human Phenotype Ontology (e.g., Lymph node hypoplasia, Cough, Hypotension). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#phenotypic_features_ids","title":"phenotypic_features_ids","text":"<p>description : The corresponding ID to the HPO vocabulary (e.g., HP:0002732, HP:0012735, HP:0002615). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#diagnosis_ids","title":"diagnosis_ids","text":"<p>description : One or more diagnoses that the entity is associated with at the time of retrieval from the organism. The diagnosis is captured using a code from ICD-10 (WHO version). Please restrict the ICD code to the chapter letter and two digits for the main diagnosis (e.g., E10, C01). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#diagnosis_terms","title":"diagnosis_terms","text":"<p>description : The ICD-10 terms corresponding to the ICD-10 codes (e.g., Type 1 diabetes mellitus, Malignant neoplasm of base of tongue). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#sex","title":"sex","text":"<p>description : The genotypic sex of the Individual (e.g., female). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>FEMALE</code> <code>A sex for clinical use value in which stereotypically or statistically \"female\" values apply to an individual in a given medical context, such as for a procedure, process, algorithm, hormone level, genetic composition, organ inventory.</code> <code>MALE</code> <code>A sex for clinical use value in which stereotypically or statistically \"male\" values apply to an individual in a given medical context, such as for a procedure, process, algorithm, hormone level, genetic composition, organ inventory.</code> <code>UNKNOWN</code> <code>A sex for clinical use value in which the stereotypical or statistical known values do not apply, cannot be determined, or are not sufficient for determination of a another value.</code> <code>OTHER</code> <code>A sex not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/Individual/#geographical_region_term","title":"geographical_region_term","text":"<p>description : The geographical region where the Individual is located. The Geographical Region is captured using a concept from the NCIT \"country\" class (NCIT:C25464) (e.g., Austria, Germany, Italy). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#geographical_region_id","title":"geographical_region_id","text":"<p>description : The corresponding ID to the NCIT vocabulary (e.g., NCIT:C16312, NCIT:C16636, NCIT:C16761). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#ancestry_terms","title":"ancestry_terms","text":"<p>description : A person's descent or lineage from a population. The Ancestry is captured using a concept from the Human Ancestry Ontology \"ancestry category\" (HANCESTRO:0004) branch (e.g., African, European, Oceanian). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#ancestry_ids","title":"ancestry_ids","text":"<p>description : The corresponding ID to the HANCESTRO vocabulary (e.g., HANCESTRO:0010, HANCESTRO:0005, HANCESTRO:0017). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Individual/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/","title":"IndividualSupportingFile","text":""},{"location":"metadata/data_dictionary/IndividualSupportingFile/#description","title":"Description","text":"<p>An Individual Supporting File is a File that contains additional information relevant for the Individual, such as ped-files, phenopackets or imaging data.</p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/IndividualSupportingFile/#format","title":"format","text":"<p>description : The file format of the Supporting File (e.g., TXT, JSON). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CSV</code> <code>Tabular data represented as comma-separated values in a text file.</code> <code>JSON</code> <code>JavaScript Object Notation format; a lightweight, text-based format to represent tree-structured data using key-value pairs.</code> <code>PED</code> <code>The PED file describes individuals and genetic data and is used by the Plink package.</code> <code>TSV</code> <code>Tabular data represented as tab-separated values in a text file.</code> <code>TXT</code> <code>Textual format. Data in text format can be compressed into binary format, or can be a value of an XML element or attribute. Markup formats are not considered textual (or more precisely, not plain-textual).</code> <code>YAML</code> <code>YAML (YAML Ain't Markup Language) is a human-readable tree-structured data serialisation language.</code> <code>OTHER</code> <code>A file format not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#individual","title":"individual","text":"<p>description : The Individual associated with an entity. required : True data type : Individual </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#name","title":"name","text":"<p>description : The given filename. required : True data type : string </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#dataset","title":"dataset","text":"<p>description : The Dataset alias associated with this File. required : True data type : Dataset </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#included_in_submission","title":"included_in_submission","text":"<p>description : Whether a File is included in the Submission or not. required : True data type : boolean </p>"},{"location":"metadata/data_dictionary/IndividualSupportingFile/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/","title":"ProcessDataFile","text":""},{"location":"metadata/data_dictionary/ProcessDataFile/#description","title":"Description","text":"<p>A Process Data File is a File that contains data produced by an Analysis or workflow.</p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/ProcessDataFile/#format","title":"format","text":"<p>description : The file format of the Process Data File (e.g., CRAM, BAM). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>BAI</code> <code>BAM indexing format</code> <code>BAM</code> <code>BAM format, the binary, BGZF-formatted compressed version of SAM format for alignment of nucleotide sequences (e.g., sequencing reads) to (a) reference sequence(s).  May contain base-call and alignment qualities and other data.</code> <code>BCF</code> <code>BCF, the binary version of Variant Call Format (VCF) for sequence variation (indels, polymorphisms, structural variation).</code> <code>BED</code> <code>Browser Extensible Data (BED) format of sequence annotation track, typically to be displayed in a genome browser. BED detail format includes 2 additional columns (http://genome.ucsc.edu/FAQ/FAQformat#format1.7) and BED 15 includes 3 additional columns for experiment scores (http://genomewiki.ucsc.edu/index.php/Microarray_track).</code> <code>CRAM</code> <code>Reference-based compression of alignment format.</code> <code>GFF</code> <code>GFF feature format (of indeterminate version).</code> <code>HDF5</code> <code>HDF5 is a data model, library, and file format for storing and managing data, based on Hierarchical Data Format (HDF).  An HDF5 file appears to the user as a directed graph. The nodes of this graph are the higher-level HDF5 objects that are exposed by the HDF5 APIs: Groups, Datasets, Named datatypes. Currently supported by the Python MDTraj package. HDF5 is the new version, according to the HDF group, a completely different technology (https://support.hdfgroup.org/products/hdf4/ compared to HDF.</code> <code>SAM</code> <code>Sequence Alignment/Map (SAM) format for alignment of nucleotide sequences (e.g., sequencing reads) to (a) reference sequence(s). May contain base-call and alignment qualities and other data. The format supports short and long reads (up to 128Mbp) produced by different sequencing platforms and is used to hold mapped data within the GATK and across the Broad Institute, the Sanger Centre, and throughout the 1000 Genomes project.</code> <code>VCF</code> <code>Variant Call Format (VCF) for sequence variation (indels, polymorphisms, structural variation).</code> <code>WIG</code> <code>Wiggle format (WIG) of a sequence annotation track that consists of a value for each sequence position. Typically to be displayed in a genome browser.</code> <code>OTHER</code> <code>A file format not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ProcessDataFile/#analysis","title":"analysis","text":"<p>description : The alias of the Analysis that produced this Process Data File. required : True data type : Analysis </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#name","title":"name","text":"<p>description : The given filename. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#dataset","title":"dataset","text":"<p>description : The Dataset alias associated with this File. required : True data type : Dataset </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#included_in_submission","title":"included_in_submission","text":"<p>description : Whether a File is included in the Submission or not. required : True data type : boolean </p>"},{"location":"metadata/data_dictionary/ProcessDataFile/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Publication/","title":"Publication","text":""},{"location":"metadata/data_dictionary/Publication/#description","title":"Description","text":"<p>A Publication represents an article that is published. The minimum expectation is that the publication has a valid DOI.</p>"},{"location":"metadata/data_dictionary/Publication/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Publication/#study","title":"study","text":"<p>description : The Study entity associated with this Publication. required : True data type : Study </p>"},{"location":"metadata/data_dictionary/Publication/#title","title":"title","text":"<p>description : The title for this Publication. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#abstract","title":"abstract","text":"<p>description : The study abstract that describes the goals. Can also hold abstract from a publication related to this Study. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#author","title":"author","text":"<p>description : Author(s) of this Publication. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#year","title":"year","text":"<p>description : The year in which the paper was published. required : False data type : integer </p>"},{"location":"metadata/data_dictionary/Publication/#journal","title":"journal","text":"<p>description : The name of the journal. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#doi","title":"doi","text":"<p>description : DOI identifier of a publication. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#xref","title":"xref","text":"<p>description : One or more cross-references for this Publication. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Publication/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/","title":"ResearchDataFile","text":""},{"location":"metadata/data_dictionary/ResearchDataFile/#description","title":"Description","text":"<p>A Research Data File is a File that contains raw data originating from an Experiment.</p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/ResearchDataFile/#format","title":"format","text":"<p>description : The file format of the Research Data File (e.g., FASTQ, uBAM, FASTA). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>FASTA</code> <code>FASTA format including NCBI-style IDs.</code> <code>FASTQ</code> <code>FASTQ short read format ignoring quality scores.</code> <code>UBAM</code> <code>Unaligned BAM file.</code> <code>FAST5</code> <code>FAST5 data format for Nanopore.</code> <code>RAW</code> <code>Raw file format for mass spectrometry proteomics data.</code> <code>D</code> <code>Raw .d files for mass spectrometry proteomics data.</code> <code>MZML</code> <code>mzML format for mass spectrometry proteomics data.</code> <code>MZDATA</code> <code>mzData for mass spectrometry proteomics data.</code> <code>OTHER</code> <code>A file format not captured by the controlled vocabulary.</code>"},{"location":"metadata/data_dictionary/ResearchDataFile/#technical_replicate","title":"technical_replicate","text":"<p>description : An integer to indicate the technical replicate of this File. required : True data type : integer </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#sequencing_lane_id","title":"sequencing_lane_id","text":"<p>description : The identifier of a sequencing lane. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#experiments","title":"experiments","text":"<p>description : The aliases of the Experiments that produced this Research Data File. required : True data type : Experiment </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#name","title":"name","text":"<p>description : The given filename. required : True data type : string </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#dataset","title":"dataset","text":"<p>description : The Dataset alias associated with this File. required : True data type : Dataset </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#included_in_submission","title":"included_in_submission","text":"<p>description : Whether a File is included in the Submission or not. required : True data type : boolean </p>"},{"location":"metadata/data_dictionary/ResearchDataFile/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Sample/","title":"Sample","text":""},{"location":"metadata/data_dictionary/Sample/#description","title":"Description","text":"<p>A Sample is a limited quantity of something to be used for testing, analysis, inspection, investigation, demonstration, or trial use.  It is prepared from a Biospecimen.</p>"},{"location":"metadata/data_dictionary/Sample/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Sample/#individual","title":"individual","text":"<p>description : The alias of the Individual entity from which this Biospecimen or Sample was derived. required : True data type : Individual </p>"},{"location":"metadata/data_dictionary/Sample/#name","title":"name","text":"<p>description : A descriptive name of this Sample (e.g., GHGAS_Blood_Sample1 or GHGAS_PBMC_RNAseq_S1). This property must not include any personally identifiable data. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#type","title":"type","text":"<p>description : The type of the Sample. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CF_DNA</code> <code>Cell Free (CF), circulating DNA was used for sequencing.</code> <code>DEPLETED_RNA</code> <code>Depleted RNA was used for sequencing.</code> <code>DS_DNA_CHIP</code> <code>Double-stranded DNA was used for sequencing.</code> <code>FFPE_DNA</code> <code>Formalin-fixed, paraffin-embedded DNA was used for sequencing.</code> <code>FFPE_TOTAL_RNA</code> <code>Formalin-fixed, paraffin-embedded total DNA was used for sequencing.</code> <code>GENOMIC_DNA</code> <code>Genomic DNA was used for sequencing.</code> <code>PCR_PRODUCTS</code> <code>PCR products were used for sequencing.</code> <code>POLY_A_RNA</code> <code>Polyadenylated (polyA) RNA was used for sequencing.</code> <code>SINGLE_CELL_DNA</code> <code>DNA originating from single cells was used for sequencing.</code> <code>SINGLE_CELL_RNA</code> <code>RNA originating from single cells was used for sequencing.</code> <code>SINGLE_CELL_NUCLEI</code> <code>RNA originating from single cell nuclei was used for sequencing.</code> <code>SMALL_RNA</code> <code>Small RNA was used for sequencing.</code> <code>TOTAL_RNA</code> <code>Total RNA was used for sequencing.</code>"},{"location":"metadata/data_dictionary/Sample/#biological_replicate","title":"biological_replicate","text":"<p>description : An integer to indicate the number of a biological replicate. required : None data type : integer </p>"},{"location":"metadata/data_dictionary/Sample/#description_1","title":"description","text":"<p>description : A concise description about the Sample source, the collection method, and the protocol which was followed to process this Sample. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#storage","title":"storage","text":"<p>description : Methods by which a Sample is stored. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>REFRIGERATOR</code> <code>The sample / biospecimen was stored in a refrigerator at 2\u00b0C to 5\u00b0C.</code> <code>FREEZER</code> <code>The sample / biospecimen was stored in a freezer at -20\u00b0C.</code> <code>ULTRA_LOW_FREEZER</code> <code>The sample / biospecimen was stored in a ultra-low freezer at -80\u00b0C.</code> <code>CRYOGENIC_FREEZER</code> <code>The sample / biospecimen was stored in a cryogenic freezer at -150\u00b0C to -190\u00b0C.</code> <code>NONE</code> <code>The sample / biospecimen was not stored.</code> <code>OTHER</code> <code>The sample / biospecimen was stored with a method differing from the available options.</code> <code>UNKNOWN</code> <code>The storage method is unknown.</code>"},{"location":"metadata/data_dictionary/Sample/#disease_or_healthy","title":"disease_or_healthy","text":"<p>description : Whether a Condition corresponds to a disease or a healthy state. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>DISEASE</code> <code>Disease state.</code> <code>HEALTHY</code> <code>Healthy state.</code> <code>NOT_APPLICABLE</code> <code>The distinction is not applicaple.</code>"},{"location":"metadata/data_dictionary/Sample/#case_control_status","title":"case_control_status","text":"<p>description : Whether a Condition corresponds to a treatment or a control. required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CASE</code> <code>The participant is a true case for the phenotype under consideration.</code> <code>CONTROL</code> <code>The participant is a true control for the phenotype under consideration.</code> <code>OTHER</code> <code>The participant's status is neither case nor control.</code> <code>UNKNOWN</code> <code>The participant's status is not known.</code>"},{"location":"metadata/data_dictionary/Sample/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#xref","title":"xref","text":"<p>description : One or more cross-references for this Sample (e.g., this Sample may have an EBI BioSamples accession ID). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_name","title":"biospecimen_name","text":"<p>description : A descriptive name of this Biospecimen (e.g., GHGAB_caudate_nucleus_biospecimen). This property must not include any personally identifiable data. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_type","title":"biospecimen_type","text":"<p>description : The type of Biospecimen. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_description","title":"biospecimen_description","text":"<p>description : A concise description about the Biospecimen source, the collection method, and the protocol which was followed to process this Biospecimen. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_age_at_sampling","title":"biospecimen_age_at_sampling","text":"<p>description : The age of the Individual at the time of isolating this biospecimen. required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>0_TO_5</code> <code>Age between 0 to 5.</code> <code>6_TO_10</code> <code>Age between 6 to 10.</code> <code>11_TO_15</code> <code>Age between 11 to 15.</code> <code>16_TO_20</code> <code>Age between 16 to 20.</code> <code>21_TO_25</code> <code>Age between 21 to 25.</code> <code>26_TO_30</code> <code>Age between 26 to 30.</code> <code>31_TO_35</code> <code>Age between 31 to 35.</code> <code>36_TO_40</code> <code>Age between 36 to 40.</code> <code>41_TO_45</code> <code>Age between 41 to 45.</code> <code>46_TO_50</code> <code>Age between 46 to 50.</code> <code>51_TO_55</code> <code>Age between 51 to 55.</code> <code>56_TO_60</code> <code>Age between 56 to 60.</code> <code>61_TO_65</code> <code>Age between 61 to 65.</code> <code>66_TO_70</code> <code>Age between 66 to 70.</code> <code>71_TO_75</code> <code>Age between 71 to 75.</code> <code>76_TO_80</code> <code>Age between 76 to 80.</code> <code>81_OR_OLDER</code> <code>Age above 80.</code> <code>UNKNOWN</code> <code>Age range unknown.</code>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_vital_status_at_sampling","title":"biospecimen_vital_status_at_sampling","text":"<p>description : Vital Status of the Individual at the time of isolating this biospecimen (e.g., alive). required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>ALIVE</code> <code>Showing characteristics of life; displaying signs of life.</code> <code>DECEASED</code> <code>The cessation of life.</code> <code>UNKNOWN</code> <code>Vital status is unknown.</code>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_tissue_term","title":"biospecimen_tissue_term","text":"<p>description : The tissue this Biospecimen originated from. Should be a term from the BRENDA Tissue Ontology vocabulary (e.g., kidney, blood, melanoma cell). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_tissue_id","title":"biospecimen_tissue_id","text":"<p>description : The corresponding ontology ID for the biospecimen_tissue_term (e.g., BTO:0000671, BTO:0000089, BTO:0000848). required : False data type : string </p>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_isolation","title":"biospecimen_isolation","text":"<p>description : Method or device employed for collecting/isolating this Biospecimen. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>BLOOD_DRAW</code> <code>Extraction of a blood specimen.</code> <code>SURGICAL_REMOVAL</code> <code>Extraction of a sample or part of an organ in a surgical procedure.</code> <code>SALIVA_COLLECTION</code> <code>Collection of saliva.</code> <code>BUCCAL_SWAB</code> <code>Sample collection using a buccal swab.</code>"},{"location":"metadata/data_dictionary/Sample/#biospecimen_storage","title":"biospecimen_storage","text":"<p>description : Methods by which this Biospecimen is stored. required : False data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>REFRIGERATOR</code> <code>The sample / biospecimen was stored in a refrigerator at 2\u00b0C to 5\u00b0C.</code> <code>FREEZER</code> <code>The sample / biospecimen was stored in a freezer at -20\u00b0C.</code> <code>ULTRA_LOW_FREEZER</code> <code>The sample / biospecimen was stored in a ultra-low freezer at -80\u00b0C.</code> <code>CRYOGENIC_FREEZER</code> <code>The sample / biospecimen was stored in a cryogenic freezer at -150\u00b0C to -190\u00b0C.</code> <code>NONE</code> <code>The sample / biospecimen was not stored.</code> <code>OTHER</code> <code>The sample / biospecimen was stored with a method differing from the available options.</code> <code>UNKNOWN</code> <code>The storage method is unknown.</code>"},{"location":"metadata/data_dictionary/Sample/#attributes","title":"attributes","text":"<p>description : Key/value pairs corresponding to an entity. required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/Sample/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Study/","title":"Study","text":""},{"location":"metadata/data_dictionary/Study/#description","title":"Description","text":"<p>A Study is an experimental investigation of a particular phenomenon. It involves a detailed examination and analysis of a subject to learn more about the phenomenon being studied.</p>"},{"location":"metadata/data_dictionary/Study/#fields","title":"Fields","text":""},{"location":"metadata/data_dictionary/Study/#title","title":"title","text":"<p>description : A comprehensive title for this Study. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Study/#description_1","title":"description","text":"<p>description : A detailed description (abstract) that describes the goals of this Study. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Study/#types","title":"types","text":"<p>description : One or more types of this Study (e.g., Cancer Genomics, Epigenetics, Exome Sequencing). required : True data type : Controlled Vocabulary </p> Permissible Values Permissible Values Description <code>CANCER_GENOMICS</code> <code>Cancer genomics</code> <code>EPIGENETICS</code> <code>Epigenetics</code> <code>EXOME_SEQUENCING</code> <code>Exome sequencing</code> <code>FORENSIC_GENETICS</code> <code>Forensic genetics</code> <code>PALEO_GENOMICS</code> <code>Paleo genomics</code> <code>GENE_REGULATION_STUDY</code> <code>Gene regulation study</code> <code>METAGENOMICS</code> <code>Metagenomics</code> <code>POOLED_CLONE_SEQUENCING</code> <code>Pooled clone sequencing</code> <code>POPULATION_GENOMICS</code> <code>Population genomics</code> <code>RNASEQ</code> <code>RNA sequencing</code> <code>RESEQUENCING</code> <code>Resequencing</code> <code>SYNTHETIC_GENOMICS</code> <code>Synthetic genomics</code> <code>TRANSCRIPTOME_ANALYSIS</code> <code>Transcriptome analysis</code> <code>WHOLE_GENOME_SEQUENCING</code> <code>Whole genome sequencing</code> <code>GWAS</code> <code>Genome Wide Association Study</code> <code>RARE_DISEASE</code> <code>Rare disease study</code> <code>CANCER</code> <code>Cancer study</code> <code>COMMON_DISEASE</code> <code>Common disease study</code> <code>NEURODEGENERATIVE_DISEASE</code> <code>Neurodegenerative disease study</code> <code>CASE_CONTROL</code> <code>Case-control study</code> <code>FAMILY</code> <code>Family study</code> <code>HEREDITARY_DISEASE</code> <code>Hereditary disease study</code> <code>GENOMICS</code> <code>Genomics study</code> <code>EPIGENOMICS</code> <code>Epigenomics study</code> <code>TRANSCRIPTOMICS</code> <code>Transcriptomics study</code> <code>SINGLE_CELL_SEQUENCING</code> <code>Single-cell sequencing study</code> <code>SINGLE_CENTER</code> <code>Single-center study</code> <code>MULTI_CENTER</code> <code>Multi-center study</code> <code>COHORT</code> <code>Cohort study</code> <code>LONGITUDINAL</code> <code>Longitudinal study</code> <code>TIME_SERIES</code> <code>Time series study</code> <code>INTERVENTIONAL</code> <code>Interventional study</code> <code>NON_INTERVENTIONAL</code> <code>Non-interventional study</code> <code>COMMUNITY_BASED</code> <code>Community-based study</code> <code>OTHER</code> <code>A study type not captured by the above mentioned.</code>"},{"location":"metadata/data_dictionary/Study/#ega_accession","title":"ega_accession","text":"<p>description : The EGA accession ID of an entity. required : False data type : string </p>"},{"location":"metadata/data_dictionary/Study/#affiliations","title":"affiliations","text":"<p>description : The affiliations associated with this Study. required : True data type : string </p>"},{"location":"metadata/data_dictionary/Study/#attributes","title":"attributes","text":"<p>description : One or more attributes that further characterize this Study. required : False data type : Attribute </p>"},{"location":"metadata/data_dictionary/Study/#alias","title":"alias","text":"<p>description : The alias for an entity at the time of submission. required : True data type : string </p>"},{"location":"snippets/submission_limitations/","title":"Submission limitations","text":"<p>Limitations on External Submissions - November 2024</p> <p>GHGA has only recently launched the functionality of the GHGA Data Portal. Our ongoing efforts concentrate on improving the data upload processes and the overall user experience for external submissions. In general, data upload by external users is not yet possible as it includes manual steps. See also this section in our FAQ and the respective user story.</p>"},{"location":"user_stories/accessing_data/","title":"Accessing Data","text":""},{"location":"user_stories/accessing_data/#creating-a-data-access-request","title":"Creating a Data Access Request","text":"<ul> <li>The GHGA Data Portal enables users to request access to data through the portal.</li> <li>For creating a 6251a85a-47d0-11ee-be56-0242ac120002:608ece0e461701c8628e28e6c84048fd:&lt;__None__&gt; you need to have a 6251a85a-47d0-11ee-be56-0242ac120002:a310a47f8fce11fbc9bc48bfd19fda7d:. <li>Browse for your dataset of interest and then click on the \"Request Access\" button. This will direct you to a data access request form. </li> <li>Complete the form with the necessary information and submit your 6251a85a-47d0-11ee-be56-0242ac120002:30739b2efec448c7171f7437e644330c:.  <li>The data access request will be sent to the 6251a85a-47d0-11ee-be56-0242ac120002:0c87107fa516fbca5be6b1cce3b14915:&lt;__None__&gt;, who will will review your request and respond accordingly. Please note that GHGA is not involved in the further process of negotiating the data access.</li> <li>To download a dataset, a valid 6251a85a-47d0-11ee-be56-0242ac120002:db21c06edbef6d13dfcd1946436e984d:&lt;__None__&gt; has to be set up for account verification in your user profile in the GHGA Data Portal. <ul> <li>The 6251a85a-47d0-11ee-be56-0242ac120002:d32eabc0a01a10ba97448f425ee4a189: also needs to be shared with the 6251a85a-47d0-11ee-be56-0242ac120002:29917be8e36d8a6211d0b056e9a98119:&lt;__None__&gt; as part of the negotiations of your request.  <li>Once the access request is approved, the 6251a85a-47d0-11ee-be56-0242ac120002:091d66c1b0e4e1672337953c264858b3:&lt;__None__&gt; will instruct GHGA to share the data only with accounts which include the proper 6251a85a-47d0-11ee-be56-0242ac120002:37fe513d71ddac33f10971f4ea661ab9:.  <p>Responsibilities for handling of data access requests</p> <p>Please note the GHGA is not responsible for deciding of data access requests as this is a responsibility of 6251a85a-47d0-11ee-be56-0242ac120002:72de6642c23a11188d9c6be295df456d:&lt;__None__&gt; installed by the the 6251a85a-47d0-11ee-be56-0242ac120002:84d29eeb5bc628466feebf3aed8e3e26:. In case you do not receive notifications about the decision on your request, please first contact the DAC as indicated on the dataset details page <p></p>"},{"location":"user_stories/accessing_data/#account-verification","title":"Account verification","text":"<p>As additional layer of safety, download tokens can only be generated by accounts that have at least one 6251a85a-47d0-11ee-be56-0242ac120002:de0cc72608034a913e71671d3100b449:&lt;__None__&gt; registered. GHGA offers multiple ways to add IVAs (Mobile Phones, Letter, in Person). A verification address can be added in the GHGA Data Portal. </p> <p>For praticability mobile phones are recommened but please note that 6251a85a-47d0-11ee-be56-0242ac120002:7d55d7e893fbbd549429f3645ac6fdbf:&lt;__None__&gt; might demand alternative means during negotiation of a 6251a85a-47d0-11ee-be56-0242ac120002:e18284482bd76f91b6edd84845eb2480:&lt;__None__&gt;.</p> <ol> <li> <p>To create and verify a contact navigate to the GHGA Data Portal.</p> </li> <li> <p>Visit your profile page to find the menu \"Contact addresses for account verification\", which lists all registered contact addresses. To add a new one, click \"New Contact Address\":</p> <p></p> </li> <li> <p>Select a contact address from SMS, Letter or In-Person. Please note, in person verification is only offered for personnel located at a GHGA Data Hub. The fastest verification can be performed via SMS.</p> <p></p> </li> <li> <p>Enter the contact information for the chosen address and confirm them by clicking \"Add unverified contact address\".</p> <p></p> </li> <li> <p>The menu \"Contact addresses for account verification\" will add the unverified address. A code for this address can be requested by clicking \"Request verification\".</p> <p></p> </li> <li> <p>A GHGA Data Steward will generate a code and transmit it via the chosen verification method. You will also be notified via mail when a code has been transmitted. Upon receival of the code, click enter verification code, enter the code and confirm the transmission. The contact address will then be shown as \"Verified\".</p> <p></p> </li> </ol> <p>If a code is not working or lost, a Data Steward can generate a new one. In case of issues, please contact the 6251a85a-47d0-11ee-be56-0242ac120002:f1cb8e337deb8e9b161c38ef80bc96d3:&lt;__None__&gt;.</p>"},{"location":"user_stories/accessing_data/#data-download","title":"Data Download","text":"<p>Downloading data from datasets you have been granted access to is a two stage process:</p> <ul> <li> <p>The download is prepared through the Data Portal. The corresponding dataset   is selected and the download potentially restricted to individual files from   the dataset. At the end of this process, a download token is generated and   shown to the user.</p> </li> <li> <p>Subsequently, the CLI tool GHGA Connector is used   to perform the actual file download using the previously generated download   token and the user's Crypt4GH key pair.</p> </li> </ul>"},{"location":"user_stories/accessing_data/#prerequisites","title":"Prerequisites","text":"<p>To perform a file download from GHGA, users are required to have genreated a Crypt4GH keypair. The public key will be used to encrypt both the download token and the actual files that are downloaded. For information on how to generate a Crypt4GH keypair please refer to the official Crypt4GH documentation.</p>"},{"location":"user_stories/accessing_data/#download-preparation","title":"Download Preparation","text":"<p>After a user has been granted access to a dataset, the user initiates a data download by creating a download token in the Data Portal. A single download token can be generated to download either a single or multiple files from a dataset. The download token is then passed on to the CLI tool GHGA Connector to perform the actual download.</p> <ol> <li> <p>Navigate to the GHGA Data Portal.</p> </li> <li> <p>Visit your profile page to see the datasets you have access to.</p> <p></p> </li> <li> <p>Navigate to the dataset list and select your dataset of interest to be downloaded.</p> <p></p> </li> <li> <p>Fill the form with the necessary information in order to create a download token. Specifying one or multiple file IDs is optional, if not information is provided the entire dataset will be downloaded. A Crypt4GH public key must be provided before submitting the form.</p> <p></p> </li> </ol>"},{"location":"user_stories/accessing_data/#download-using-ghga-connector","title":"Download using GHGA Connector","text":"<p>The GHGA Connector is a command-line tool that facilitates interaction with the file storage infrastructure of GHGA. Data downloading is carried out using the GHGA Connector.</p> <p>For further information on how to use the command-line tool, please refer to the GHGA Connector documentation.</p>"},{"location":"user_stories/browsing_data/","title":"Browsing Data","text":"<p>The GHGA Data Portal is a secure national infrastructure for human omics data available under controlled access. To browse data, please visit the GHGA Data Portal at data.ghga.de/ and got to the \"Browse\" page..</p>"},{"location":"user_stories/browsing_data/#views","title":"Views","text":""},{"location":"user_stories/browsing_data/#overview","title":"Overview","text":"<p>The first view shows you an overview of all available datasets on GHGA.</p>"},{"location":"user_stories/browsing_data/#filtering","title":"Filtering","text":"<ul> <li> <p>On the left various filter options are available to filter for desired properties of datasets.</p> <ul> <li>Select filters and click \"Filter\" on the bottom-left to apply the filters to the list of datasets shown on the right.</li> <li>This will lead to a reduced number of datasets shown in the listing on the right. Filters can be removed by just clicking the \"x\" on the applied filters on the top of the list.</li> </ul> <p></p> </li> </ul>"},{"location":"user_stories/browsing_data/#dataset-details-overview","title":"Dataset details overview","text":"<ul> <li>To see more details of a dataset, just click on the list item. An extended view of this dataset will appear: </li> <li>The following functionalities can be accessed from that page:<ul> <li>\"EGA Dataset\": In case the dataset is in addition listed on the EGA-Archive, this will open a new tab with the corresponding dataset detail page on EGA.</li> <li>\" Request Access\": In case you would like to use this dataset, this button opens (after login) a form to request access to the dataset. See Accessing Data for further details.</li> <li>\"Dataset details\" opens a detailed view of the dataset, see below.</li> </ul> </li> </ul>"},{"location":"user_stories/browsing_data/#dataset-details","title":"Dataset details","text":"<ul> <li>Once you have clicked on the \"Dataset details in the Overview, you will be forwarded to the Dataset details view. This view contains further information on the datasets metadata e.g.:<ul> <li>Study description</li> <li>Linked publications</li> <li>Data Access Details</li> <li>Experiment Summary</li> <li>Sample Summary</li> <li>File Summary</li> </ul> </li> <li>Details on the nature of these fields are described in the documentation on the Metadata Model used. </li> </ul>"},{"location":"user_stories/dua-guideline/","title":"Data Use and Access Guidelines","text":""},{"location":"user_stories/dua-guideline/#purpose-of-this-article","title":"Purpose of this Article","text":"<p>The purpose of this document is to provide 6251a85a-47d0-11ee-be56-0242ac120002:8a0c3e5a2f2bcfdf09389c7ceb9be1f5: with guidance on how to make decisions about 6251a85a-47d0-11ee-be56-0242ac120002:57d31c0fb5366b701472b4f99ed1883c:&lt;__None__&gt; for data they have archived in GHGA. The document identifies ethical and organisational standards regarding operating procedures and decision-making criteria. <p>Please refer to the glossary for definitions of capitalised terms.</p>"},{"location":"user_stories/dua-guideline/#introduction","title":"Introduction","text":"<p>6251a85a-47d0-11ee-be56-0242ac120002:a7dccc14461850e6df8d5faa0e04758c:&lt;__None__&gt; such as 6251a85a-47d0-11ee-be56-0242ac120002:a4aa83efd5de3467aadfca0b207c61e0:&lt;__None__&gt; and other forms of genetic and health data used for scientific research purposes is considered sensitive personal data (special category data under Art. 9 GDPR) due to its informational content and the inherent risk of re-identification associated with it. A whole genome sequence is unique to an individual and so has the potential to differentiate them from the wider population. Moreover, the combination of Omics Data with clinical data in research carries further informational risks for the identifiable person as information about their current and future health could also be attributed to them.</p> <p>6251a85a-47d0-11ee-be56-0242ac120002:171e110ea92c69fd1167b71b7ea9eb52:&lt;__None__&gt; that is archived by GHGA for secondary use in scientific research is therefore subject to controlled access (see GHGA Terms of Use). As part of data submission to GHGA, the 6251a85a-47d0-11ee-be56-0242ac120002:b74ec47986bd91c6cc7b5a2a2862cbd1:&lt;__None__&gt; are therefore advised to implement a review process for 6251a85a-47d0-11ee-be56-0242ac120002:1006ace8a52a37bb96c474a42571b1ca: to ensure compliance with legal and ethical standards, especially to protect individual privacy."},{"location":"user_stories/dua-guideline/#review-of-data-access-requests","title":"Review of Data Access Requests","text":"<p>6251a85a-47d0-11ee-be56-0242ac120002:2a65bb14aa6e3bd65b65f938f0d3a9f4: wishing to access datasets stored by GHGA must first make a Data Access Request that specifies their proposed research project, its purpose and aims, the responsible persons, and the datasets to be used. These requests are forwarded to the 6251a85a-47d0-11ee-be56-0242ac120002:03b0fc723acba749f3c9eab7030411d0:&lt;__None__&gt; for the datasets in question (usually identical with the Data Submitter). <p>Data Access Requests need to be reviewed by a 6251a85a-47d0-11ee-be56-0242ac120002:ee89d1a43ff32cb2fa3511d8ddcffad0:&lt;__None__&gt; appointed by the RDC, and not by GHGA. The DAC is responsible for authorising access to the particular datasets that the Research Data Controller has defined. Access is only granted after a positive decision by the DAC has been communicated to GHGA.</p> <p>The following sequence diagram shows the involved parties and key steps to process a Data Access Request coming in via GHGA.</p> <pre><code>sequenceDiagram\n title Simplified Depiction of the Process to Handle Data Access Requests (DAR) using GHGA\n   box rgb(204, 229, 255) Data Requester\n      participant DR as Data Requester\n   end\n   box rgb(207, 251, 205) GHGA\n      participant GHGA as GHGA Data Portal\n   end\n   box rgb(255, 229, 204) Data Controller\n      participant DAC\n      participant RDC as Research Data&lt;br/&gt;Controller\n   end\n   autonumber\n   rect rgb(250, 250, 250)\n   note over DR, GHGA: Dataset Identification\n   DR -&gt;&gt; GHGA : Dataset Search\n   activate GHGA\n   GHGA -&gt;&gt; DR : Information on matching dataset\n   deactivate GHGA\n   end\n   rect rgb(250, 250, 250)\n   note over DR, RDC: Negotiation of Data Access Request\n   DR -&gt;&gt; GHGA : Files Data Access Request (DAR) &lt;br/&gt; at Data Portal\n   activate GHGA\n   GHGA -&gt;&gt; DAC : Forwards DAR\n   deactivate GHGA\n   DAC -&gt;&gt; DR : Requests necessary information and forwards DTA Template\n   DR -&gt;&gt; DAC : Sends information on research project and signed DTA\n   DAC -&gt;&gt; RDC : Informs RDC institution on decision &lt;br/&gt;(Acceptance / Rejection)\n   RDC -&gt;&gt; DR : Informs Data Requester on decision outcome. &lt;br/&gt;If positive sends countersigned DTA\n   end\n   rect rgb(250, 250, 250)\n   note over DR, RDC: Decision Implementation / Data Download\n   RDC -&gt;&gt; GHGA : Informs GHGA on decision on  DAR&lt;br/&gt; (Acceptance /Rejection)\n   GHGA -&gt;&gt; DR : Informs DR on decision. &lt;br/&gt; If positive provides download link\n   end</code></pre> <p>The primary objective of DACs is to oversee the access to Research Data. In contrast to 6251a85a-47d0-11ee-be56-0242ac120002:888b250f3740a84113802d563a69feda: (Institutional Review Boards) that assess the full range of ethical issues associated with research projects, a DAC usually evaluates whether the proposed use of data is compatible with the data use conditions, in particular those specified in the data subject\u2019s consent. <p>We recommend that DACs authorising access to data deposited with GHGA establish a set of documents to serve as a basis for them to operate and reach decisions. These will usually include terms of reference (TOR) and standard operating procedures (SOP) for the DAC as well as a list of criteria for data access decisions and a Data Transfer Agreement (DTA) template. These documents are further described below.</p>"},{"location":"user_stories/dua-guideline/#key-documents-recommended-for-dac-operation","title":"Key Documents Recommended for DAC Operation","text":""},{"location":"user_stories/dua-guideline/#dac-terms-of-reference-tor","title":"DAC Terms of Reference (TOR)","text":"<p>The terms of reference (TOR) define the purpose, set-up, scope, and structure of the DAC. The TOR should be documented and subject to change through a predefined process (see last bullet point of the SOP). For transparency reasons, it should be possible to make the TOR available to other interested parties upon request.</p> <p>The TOR should specify:</p> <ul> <li> <p>The role and purpose of the DAC;</p> </li> <li> <p>The relationship between the DAC and the Research Data Controller (e.g.: Is the DAC part of the data-controlling institution or has an external DAC been appointed by the Research Data Controller?);</p> </li> <li> <p>The particularities of membership (e.g.: How many permanent and associate members does the DAC have? Who are the members and what are their areas of expertise? How are members appointed?);</p> </li> <li> <p>A description of the different roles and responsibilities within the DAC, if applicable (e.g.: Chair, Co-chair);</p> </li> <li> <p>The period of service of the DAC and/or its members;</p> </li> <li> <p>The nature and structure of DAC meetings and communication (as specified in more detail in the SOPs);</p> </li> <li> <p>The process by which other parties at the Research Data Controller\u2019s institution can be involved, e.g. the data protection officer or the legal department.</p> </li> </ul>"},{"location":"user_stories/dua-guideline/#dac-standard-operating-procedures-sops","title":"DAC Standard Operating Procedures (SOPs)","text":"<p>The standard operating procedures (SOP) define how the routine tasks of the DAC should be carried out and help DAC members to work in an efficient and consistent manner. The SOP should be documented and subject to change through a predefined process (see last bullet point of the SOP). For transparency reasons, it should be possible to make the SOP available to other interested parties upon request.</p> <p>The SOP should specify:</p> <ul> <li> <p>The nature and structure of DAC communications, including the means of correspondence (e.g.: emails, virtual meetings, in-person meetings);</p> </li> <li> <p>The nature and structure of DAC meetings, including the frequency and approximate length of meetings;</p> </li> <li> <p>The nature and structure of DAC correspondence with GHGA and Data Requesters (e.g.: How will the Data Requester be notified of a review outcome?);</p> </li> <li> <p>The estimated, or usual, time taken for review decisions;</p> </li> <li> <p>The range of possible review outcomes (e.g.: approval, refusal, revision);</p> </li> <li> <p>The type of consensus required for review decisions (e.g.: unanimity, majority vote, quorum);</p> </li> <li> <p>The process of a criteria-based access review (this is complemented by the LOC below);</p> </li> <li> <p>The process for submitting an appeal or a revised application after a negative decision;</p> </li> <li> <p>The method of compiling statistics regarding KPIs (e.g.: number of applications approved/rejected, average time taken);</p> </li> <li> <p>The method for reviewing decisions in order to improve DAC performance;</p> </li> <li> <p>The process of modifying the TOR, SOP, and LOC (e.g.: How can members suggest and make amendments?).</p> </li> </ul>"},{"location":"user_stories/dua-guideline/#list-of-criteria-loc-for-data-access-decisions","title":"List of Criteria (LOC) for Data Access Decisions","text":"<p>Each DAC should establish a list of criteria (LOC) that govern the review process and harmonise this process across Data Access Requests. The LOC should be documented and subject to change through a predefined process (see last bullet point of the SOP). For transparency reasons, it should be possible to make the LOC available to other interested parties upon request.</p> <p>Access requests should be checked against these items:</p> <ol> <li> <p>The proposed research has received a positive ethics vote or an ethics approval from a credible source, e.g. a 6251a85a-47d0-11ee-be56-0242ac120002:31854bb0a9d6fdaa44c3f7ef12d52b2e:&lt;__None__&gt;, if applicable.</p> </li> <li> <p>The identity and institutional affiliation of the Data Requester is verified and the Data Requester and their institutions are trustworthy.</p> </li> <li> <p>There are no data protection concerns that require further attention (see last section on Data Protection Assessment); if such concerns exist or if data is to be transferred across national borders, the DAC should check with the legal department or data protection officer at the Research Data Controller\u2019s institution if data transfer is lawful.</p> </li> <li> <p>There is sufficient evidence that the Data Requester requires access to the particular datasets in order to carry out the proposed research.</p> </li> <li> <p>There is sufficient evidence that the intended methods and procedures are appropriate to address the research question and that the research project is in line with the standards of good scientific practice.</p> </li> <li> <p>There is sufficient evidence that the intended data processing is taking place in a safe setting that prevents unauthorised access.</p> </li> <li> <p>There is sufficient evidence that the intended data use is compatible with the legal and ethical use conditions associated with the particular datasets, especially with the conditions and restrictions outlined in the data subjects\u2019 consent.</p> </li> <li> <p>There is sufficient evidence that appropriate measures are in place to protect the informational rights of data subjects and other parties (such as family members), including the right to erasure, and to manage and minimise potential risks (e.g., of re-identification).</p> </li> </ol>"},{"location":"user_stories/dua-guideline/#data-transfer-agreement-dta","title":"Data Transfer Agreement (DTA)","text":"<p>Before access is granted, the Research Data Controller needs to ensure that the Data Requester is contractually bound to comply with any applicable regulations concerning the exchange of the date. For this a 6251a85a-47d0-11ee-be56-0242ac120002:5e93f5ab2ed0fc3704d849572307b571:&lt;__None__&gt; needs to be agreed upon between the Research Data Controller and the Data Requester. The DTA establishes the contractual basis for granting data access/transfer and ensures that all parties involved are aware of their responsibilities and obligations regarding data handling and data protection.</p>"},{"location":"user_stories/dua-guideline/#using-the-independent-verification-adress-iva-to-verify-identities","title":"Using the Independent Verification Adress (IVA) to verify identities","text":"<ul> <li> <p>To download data from GHGA, users need to have a verified account (see here), which is linked to:</p> <ol> <li>a 6251a85a-47d0-11ee-be56-0242ac120002:0694ea4e2d3e1f58592a6e5e2d805916:&lt;__None__&gt; Acount</li> <li>a 6251a85a-47d0-11ee-be56-0242ac120002:d0c84b967ab65d4fa3720060d78d199a:&lt;__None__&gt;</li> </ol> </li> <li> <p>The 6251a85a-47d0-11ee-be56-0242ac120002:cb381c6afd3327d474f1e68df2135968:&lt;__None__&gt; should verify the IVA of the requester independently of GHGA (by e.g. calling the requester on this number or sending a secret code to the IVA which then should be returned via mail) and should then inform GHGA that this IVA should be used for the data download.</p> </li> </ul>"},{"location":"user_stories/dua-guideline/#data-protection-assessment","title":"Data Protection Assessment","text":"<p>A critical aspect of processing a Data Access Request is the assessment of the data protection aspects of the proposed sharing. This assessment focuses on compliance with the General Data Protection Regulation (GDPR), especially regarding an appropriate legal basis for data processing. If a Data Processing Impact Assessment (DPIA) has been conducted in accordance with Art. 35 GDPR, care should be taken that the risks that may emerge from data sharing have also been considered. GHGA has performed a risk assessment and produced a related report of the potentials risks that could emerge within the scope of its processing, and these can be made available upon request.   </p> <p>The aim of the data protection assessment is to ensure that granting data access to a Data Requester aligns with legal standards and that the rights of individuals are respected. Each institution operating a DAC should have a designated data protection officer.</p> <p>If the request involves complex issues, or is not clearly regulated in terms of data protection, the DAC\u2019s institution, in consultation with the DPO, may either consult the institution's 6251a85a-47d0-11ee-be56-0242ac120002:5eb0ed7dd7cb25c8c3ad5627d4567e3b:&lt;__None__&gt; or decide to create a dedicated board to deal with such edge cases and to carry out a documented balancing of legal and other interests together with the DAC.</p>"},{"location":"user_stories/submission/data_availability_statement/","title":"Data Availability Statement","text":"<p>To reference a study included in the GHGA Archive in publications or other media, please always reference the study accession, e.g. <code>GHGAS12079965883832</code>. This accession number serves as umbrella for all datasets included in the related study. We recommend using the following statement to reference the data deposition in journals:</p> <p>Data Availability Statement</p> <p>The data generated in this study are available via controlled access in the German Human Genome-Phenome Archive (GHGA, data.ghga.de) under GHGA Accession GHGAS12079965883832. Further details, including the data access policy for the study, can be found there.</p> <p>This reference should be used instead of a direct link to the submission as these links might render invalid eventually. The accession number will stay valid in any case.</p>"},{"location":"user_stories/submission/dpc_preparation/","title":"Preparation of a GHGA Data Processing Contract for submission to GHGA Archive","text":""},{"location":"user_stories/submission/dpc_preparation/#introduction","title":"Introduction","text":"<p>A 6251a85a-47d0-11ee-be56-0242ac120002:066d80090a95307e0536653dc6effcec:&lt;__None__&gt; is signed by 6251a85a-47d0-11ee-be56-0242ac120002:a119dfd704782ea2a97295ba07e34767:&lt;__None__&gt; and an institution that is the 6251a85a-47d0-11ee-be56-0242ac120002:b5189e26231cbb834b6ecc26513432d3:&lt;__None__&gt; when they wish to submit data to GHGA. The DPC sets out how GHGA may process the data, the role of the 6251a85a-47d0-11ee-be56-0242ac120002:c14094648697c8b202d9d0f6d4318a3d:, and what the Data Controllers\u2019 responsibilities are.  <p>: The DPC is available here  for download.</p> <p>The DPC creates a controller-to-processor relationship between the institution and GHGA Central. It has been designed to conform with Art. 28 GDPR Nr. 3.</p> <p>The difference between a Data Controller and a Data Submitter</p> <p>The GDPR defines a Data Controller as the party which \"determines the purposes and means of the processing of personal data\". Within the context of GHGA, we also use the term Data Submitter to mean the person or institution who are submitting Research Data to the GHGA Data Portal. In many cases, the Data Controller and Data Submitter will be the same but this is not always true; it is therefore important for the Data Submitter to check who the Data Controller is for the data they wish to submit. In this guide, we will use the term Data Controller, as it is the Data Controller who is required to sign the GHGA Data Processing Contract.</p>"},{"location":"user_stories/submission/dpc_preparation/#data-submission-to-ghga-from-dkfz-scientists","title":"Data Submission to GHGA from DKFZ Scientists","text":"<p>For submissions in which the DKFZ is the 6251a85a-47d0-11ee-be56-0242ac120002:ab863b0cb2ba1b42e125adc2ba7fef15:&lt;__None__&gt;, instead of agreeing to a 6251a85a-47d0-11ee-be56-0242ac120002:32c18049b4afb05124cced40518e521c: the responsible scientists need to sign the DKFZ Internal Terms of Use for data deposition in GHGA. The Internal Terms of Use are availbe here in the DKFZ Intranet."},{"location":"user_stories/submission/dpc_preparation/#checklist-for-legal-pre-requisites-for-data-submission-to-ghga","title":"Checklist for legal pre-requisites for data submission to GHGA","text":"<p>The following checklist gives an overview on the necessary legal processes to be carried out before a data submission to GHGA can be performed.</p> <ul> <li> <p> Download and review the terms of the GHGA Data Processing Contract.</p> <ul> <li>An explanation of the GHGA Data Processing Contract is provided below.</li> </ul> </li> <li> <p> Identify the Data Controller.</p> <ul> <li>As the GHGA Data Processing Contract can only be signed by the Data Controller, it is important to identify who they are. </li> <li>In cases where the data are jointly-controlled, only one of the Data Controllers is required to sign the contract.</li> </ul> </li> <li> <p> Consider the additional information that is required. </p> <ul> <li>A number of the annexes to the GHGA Data Processing Contract require information from the Data Controller. It is important for the Data Controller to consider in advance how they will respond.</li> </ul> </li> <li> <p> Submit a Pre-Submission Inquiry or contact us via the 6251a85a-47d0-11ee-be56-0242ac120002:5b898e89cbf3db87f8ccdb4d0588f4d3:&lt;__None__&gt;. GHGA will send you feedback whether or not the intended submission can be supported.</p> </li> <li> <p> Determine the authorised signatory person for the Data Controller.</p> <ul> <li>Different institutions will define differently which roles are authorised to sign contracts on their behalf. It is not typical that an individual researcher can alone sign a contract. </li> </ul> </li> <li> <p> Submit detailled information to complete the DPC.</p> <ul> <li>If the proposed data submission can be supported by GHGA, the Data Controller will be asked by GHGA to supply the information necessary to prepare a bespoke Data Processing Contract for the Data Controller. This includes details such as the address of the institutions, signatories, persons authorised to act, and a description of the data to be submitted. GHGA will then provide the Data Controller with a sign-ready PDF-version of the DPC.</li> </ul> </li> <li> <p> Submit the signed Data Processing Contract to GHGA for counter-signing and propossing. </p> </li> </ul>"},{"location":"user_stories/submission/dpc_preparation/#details-on-signing-procedure","title":"Details on Signing Procedure","text":"<ul> <li> <p>The signing can be carried out either using \"wet ink\" or a qualified electronic signature:</p> <ul> <li> <p>For wet ink signing (preferred), submit two physical copies of the signed contract to GHGA Central using the following address:</p> <pre><code>DKFZ Heidelberg\nGHGA (German Human Genome-Phenome Archive) - W620\nIm Neuenheimer Feld 280\nD-69120 Heidelberg\n</code></pre> </li> <li> <p>For electronic signing a qualified electronic signature (QES) is required in accordance with Article 3(12) of the eIDAS Regulation (EU) No. 910/2014 and Section 126a of the German Civil Code (BGB). Such a signature can be provided using certified services like DocuSign, IDnow, or other providers.</p> </li> </ul> </li> </ul>"},{"location":"user_stories/submission/dpc_preparation/#the-ghga-data-processing-contract","title":"The GHGA Data Processing Contract","text":"<p>The DPC is structured in two parts. The first part, comprised of the sections Preamble to \u00a77 - Signing, focuses on the services that GHGA offers to the Data Controller once they have signed a DPC. The second part of the DPC are the Annexes which focus on the data protection aspects that relate to the different data types which are processed under the DPC. There are sections within the Annexes for which the Data Controller must provide information.</p>"},{"location":"user_stories/submission/dpc_preparation/#sections-in-the-first-part","title":"Sections in the First Part","text":"<p>A brief summary of these sections is presented below.</p> <p>Preamble - This section introduces GHGA and the objectives of the project.</p> <p>\u00a71 - Definitions - This section defines the specific GHGA-related terms used within the DPC.</p> <p>\u00a72 - Purpose of this Agreement - This sections describes the services that GHGA offers to Data Controllers. These services are:</p> <ol> <li> <p>The storage of Research Data.</p> </li> <li> <p>The publication of Non-personal Metadata that describes the Research Data in the GHGA Data Portal.</p> </li> <li> <p>Quality control checks performed upon the Research Data, Personal Metadata, and Non-personal Metadata.</p> </li> <li> <p>The storage of any Personal Metadata related to the Research Data.</p> </li> <li> <p>Additional processing of the Research Data to assess and enhance its quality.</p> </li> <li> <p>Support to make the Research Data and Personal Metadata accessible to approved Data Requesters. </p> </li> <li> <p>GHGA Central shall operate a Helpdesk service through which Service Users including the Data Submitter can receive support.</p> </li> </ol> <p>A fuller description of these services is provided in the DPC.</p> <p>\u00a73 - Right to Termination - This section explains in what circumstances the DPC can be terminated. Both parties have the right to cancel the DPC if the other fails to meet their obligations. The Data Controller can also cancel the DPC whenever they wish.</p> <p>\u00a74 - Process for the Termination of the Agreement - This section sets out the process followed in the event that a DPC is cancelled. The data that has been deposited will either be returned to the Data Controller or destroyed depending on the preferences of the Data Controller. If a DPC is cancelled because the Data Controller is unresponsive, GHGA may be forced to destroy the data has been deposited. </p> <p>\u00a75 - Warranties and Liabilities - This section describes the warranties and liabilities for each party in the event that there are damages resulting from the submission of data. GHGA commits to making a reasonable effort to retreive any data in the event of a loss, but that this effort is limited to what is reasonable for GHGA to do.</p> <p>\u00a76 - Final Provisions - This section includes additional clauses that affect the DPC including how changes to the contract can be made.</p> <p>\u00a77 - Signing - This section is signed by the Data Controller and GHGA Central. See the checklist above for details on types of accepted signatures.</p>"},{"location":"user_stories/submission/dpc_preparation/#annexes","title":"Annexes","text":"<p>A brief summary of the annexes is presented below.</p>"},{"location":"user_stories/submission/dpc_preparation/#annex-1-research-data-transferred-by-the-the-data-submitter","title":"Annex 1 - Research Data Transferred by the the Data Submitter","text":"<p>In Annex 1, the Data Controller is required to list the datasets or studies that they wish to submit to GHGA, and to provide information about them. This information is used to decide which GHGA Data Hub is best placed to process the submission. Only data or studies which are listed in Annex 1 can be submitted under the DPC. Any future submission will require another DPC. </p> <p>The Data Controller must also provide contact information about how Data Requesters can make a request to access the data. This needs to be a functional institutional email address and can not contain personal information. Usually this is the email address of the 6251a85a-47d0-11ee-be56-0242ac120002:6ef147168277c57e5e1d61e05261c076:&lt;__None__&gt;. The same information will also need to be submitted as part of the metadata submission as part of the information on the Data Access Committee.</p>"},{"location":"user_stories/submission/dpc_preparation/#annex-2-ghga-data-hubs","title":"Annex 2 - GHGA Data Hubs","text":"<p>In Annex 2, GHGA will list all of the institutions that have been fully onboarded as GHGA Data Hubs and will be acting as sub-processors to GHGA Central. The GHGA Data Hubs will be responsible for storing Research Data and Personal Metadata on behalf of GHGA Central. </p>"},{"location":"user_stories/submission/dpc_preparation/#annex-3-transfer-of-research-data-and-personal-metadata-from-the-data-submiter-to-ghga-central-in-accordance-with-article-28-gdpr","title":"Annex 3 - Transfer of Research Data and Personal Metadata from the Data Submiter to GHGA Central in Accordance with Article 28 GDPR","text":"<p>Annex 3 utilises the Standard Contractual Clauses developed by the European Commission for controller-to-processor relationships to govern the processing of Research Data and Personal Metadata. The template produced by the European Commission has been adapted to refer to GHGA Central and the GHGA Data Hubs. </p>"},{"location":"user_stories/submission/dpc_preparation/#annex-4-persons-authorised-to-act","title":"Annex 4 - Persons Authorised to Act","text":"<p>Annex 4 asks the Data Controller for 6251a85a-47d0-11ee-be56-0242ac120002:eea6ae9e3a52735ece6c6f0c649ea943:. It is expected that for a majority of submissions to GHGA, an institution rather than an individual scientist will be the Data Controller. It is also expected that the people who represent their institutions, such as a Management Board, Chancellor, or Director, are not likely to be responsible for submitting data to GHGA. As such, we require the Data Controller to name people who can act on their behalf so that we can be sure that the instructions we receive from those people are legally valid. <p>In order to ensure that only authorised people can access our systems, GHGA utilises Life Science Login (LS Login) to authenticate users. Therefore, the DPC requires the Data Controller to include the LS Login IDs of the persons who they authorise to act. The process for obtaining LS Login IDs is described below. </p> <p>In addition, in order to ensure secure communications between GHGA and the named persons authorised to act, an 6251a85a-47d0-11ee-be56-0242ac120002:904dfd931b81e79d2ea5052318ea1160:&lt;__None__&gt; is required from the named individuals.</p>"},{"location":"user_stories/submission/dpc_preparation/#annex-5-processing-of-non-personal-metadata","title":"Annex 5 - Processing of Non-personal Metadata","text":"<p>Annex 5 sets out the Data Controller's obligations with regards to the submission of Non-personal Metadata that will be displayed publicly in the GHGA Data Portal. The Data Controller is required to confirm that the metadata they are submitting is non-personal.</p>"},{"location":"user_stories/submission/dpc_preparation/#annex-6-the-processing-of-personal-data-to-fulfil-this-agreement","title":"Annex 6 - The Processing of Personal Data to fulfil this Agreement","text":"<p>In order for GHGA to fulfil a Data Processing Contract it will be necessary to process personal Administrative Data, e.g. contact information about people who have been authorised to act on behalf of the Data Controller. Annex 6 describes the processing of personal Administrative Data, the legal basis for doing so, and the rights of the Data Subjects.</p> <p>For approved Data Access Requests, it will be necessary that a person authorised to act on behalf of the Data Controller submits the following information to GHGA Central:</p> <ul> <li>Name of the approved Data Requester</li> <li>6251a85a-47d0-11ee-be56-0242ac120002:d3dba99cc5bc9d7021ecf21336f67c25:&lt; Life Science Login ID&gt;</li> <li>6251a85a-47d0-11ee-be56-0242ac120002:874d741e30a165791df19e155f38a253:&lt;__None__&gt;</li> </ul>"},{"location":"user_stories/submission/dpc_preparation/#specification-of-ls-login-ids-for-usage-in-contracts","title":"Specification of LS Login IDs for usage in contracts","text":"<p>To be able to process 6251a85a-47d0-11ee-be56-0242ac120002:2d74bc2bec9e683ffe5e8d9391c54819:&lt;__None__&gt; and for others uses, GHGA users need to specify details of their LS Login ID to GHGA. The following information is needed:</p> Field Explanation Name The name of the person, e.g. <code>Doe, Jane</code> Organisation Name of the Organisation / Institution that interacts with GHGA, e.g. <code>Doe Institut</code> Role Your role in the Organisation, e.g. <code>Data Steward</code> Contact Information An email adress, e.g. <code>Jane.doe@doe-institut.xyz</code> Life Science Login ID / LS ID The LS ID e.g. as displayed in your LS ID user profile, e.g. <code>777xc437f725f58660456780tt01d5l999f9b123456@lifescience-ri.eu</code>. Further information"},{"location":"user_stories/submission/submitter_guide/","title":"Data Preparation Guide","text":""},{"location":"user_stories/submission/submitter_guide/#1-initiation-of-a-submission","title":"1. Initiation of a submission","text":"<p>To initiate a submission of data to GHGA, please contact us by completing the pre-submission enquiry, which collects general information about the plannend submission. A GHGA Data Steward will be assigned and guide you through the process, which consists of the following steps:</p> <p></p> <ol> <li>Signing of a Data Processing Contract, see here.</li> <li>Preparation of the non-personal metadata</li> <li>Research Data File submission</li> </ol> <p>The signing of a DPC has to be finalized before a Data Steward is allowed to interact with the non-personal metadata. Preparation of the metadata and file submission can be done on the submitter side in parallel.</p>"},{"location":"user_stories/submission/submitter_guide/#2-metadata-preparation","title":"2. Metadata preparation","text":"<p>The GHGA metadata model aims at facilitating comprehensive submissions that maximize the amount of collected metadata in a FAIR manner. Submissions can be either prepared in JSON format or by using a submission spreadsheet. An example submission can be found in our Github repository containing example data. The provided metadata are categorized as Research Metadata and Administrative Metadata, whereas the former collect information about the experimental and data acquisition process and the latter about data access, rights management and disposition. It is crucial, that only non-personal metadata are submitted to GHGA.</p> <p></p>"},{"location":"user_stories/submission/submitter_guide/#research-metadata","title":"Research Metadata","text":"<p>To provide a streamlined submission of metadata, the model is designed to closely resemble a bottom-up-omics experiment:</p> <p>Similar to an experimental procedure, Individuals that are subject to investigation should be defined first.  In order to describe an individual, data submitters are required to provide information about sex and are recommended to provide information about phenotypic features and diagnoses.  To maximize the FAIRness of the provided metadata, phenotypic features shoulde be entered using the Human Phenotype Ontology (HPO) and diagnosis via ICD-10.</p> <p>In the next step, the collection of biological material from individuals is described via Sample and Biospecimen. Biospecimen is defined in GHGA's metadata as any natural material taken from a biological entity for testing, diagnostics, treatment or research purposes. The sample is linked to the individual and defined as a limited quantity of something to be used for testing, analysis, inspection, investigation, demonstration, or trial use. </p> <p></p> <p>The modules Experiment and Experiment Method capture information about the protocol that was followed to perform the omics experiment to define the data acquisition process. The experimental method has to be defined once for each different type of experimental setup, e.g. bulk WGS or single cell RNA, whereas an experiment describes the measurement that was performed of a sample with this experimental approach to generate a Research Data File. Therefore, sample and experimental methods are both linked to an experiment.</p> <p>A Research Data File is linked to an experiment as it is defined as the raw output from the data acquisition process. Information about the file format as well as technical replicate should be provided here. Checksum and file size are automatically generated upon file upload and do not need to be specified again. The file alias should match the name of the submitted file to connect the specified metadata to the Research Data File.</p> <p></p> <p>The classes Analysis and Analysis Method function similar to Experiment and its methods to describe the process of data acquisition from a linked Research Data Files by downstream processing. The analysis method has to be provided once for the analytical approach or used workflow, analysis describes the processing that was performed to generate a Process Data File.</p> <p>Process Data Files are the output of an analysis and linked to it. The class functions similar to a Research Data File and requires submitters to define the matching file alias, type and analysis that generated them to link them to the remaining metadata.</p> <p></p> <p>Additionally, the submitter can embellish the classes with Supplementary files, such as experimental protocols for the experiment class, workflow parameter files for the analysis class or structured metadata files, such as phenopackets or PED files for the individual class.  Supplementary files are encrypted and inaccessible without an accepted data access request.  This allows submission of metadata that should not be publicly visible as it can only be accessed by requesters after the data controller has approved a data transfer request and the data is made available via the portal to the data requester. Hence, the data portal will only indicate the presence of supplementary files for classes and signify that a submission contains additional information, e.g. in the form of encrypted phenopackets for individuals, but not process or show their content.</p>"},{"location":"user_stories/submission/submitter_guide/#administrative-metadata","title":"Administrative Metadata","text":"<p>Once the experimental and analytic approach as well as the file generation have been described, the submitter can define the conditions on how to share the data.</p> <p></p> <p>For this, all submitted file types are linked to and presented in Datasets that allow submitters to provide a high-level description of its content and define under which data use conditions the content of the dataset can be shared by providing Data Use Ontology (DUO) codes. </p> <p>Each dataset is managed by a Data Access Committee that defines a Data Access Policy to describe clear guidelines for data requesters to access the data. The Data Access Committee should consist of multiple members and provide a non-personal mail address that forwards mail to each member of the DAC to decrease the risks of abandoned or unresponsive DACs.</p> <p>Lastly, a Study is defined to outline the research intent of the submission. For this, study title, abstract and information about the journal where the study is published (if available) are collected. An alias for the study has to be defined, to link the datasets of the submission. If present, also the Publication in which the data is referred can be described.</p>"},{"location":"user_stories/submission/submitter_guide/#use-case-examples","title":"Use case examples","text":"<p>The GHGA metadata model enables submitters to represent a wide range of experimental and analytic approaches of omics studies. Different experimental methods require different entities in the classes, whereas only the relevant ones are exposed to the submitter via different spreadsheets. The \u201ccore set\u201d of classes in contrast stays immutable and describes approach- agnostic metadata that can be used to describe the general experiment design. The following tables show a set of common use-cases linearized to the long format for the submitted files for better readability:</p>"},{"location":"user_stories/submission/submitter_guide/#studies-with-casecontrol-samples","title":"Studies with case/control samples:","text":"<p>Table 1 - Case or control is an entity on the sample level and is linked to files via experiment.</p>"},{"location":"user_stories/submission/submitter_guide/#studies-with-technical-and-biological-replicates","title":"Studies with technical and biological replicates","text":"<p>Table 2 - Biological replicate information can be collected similarly on the sample level, technical replicates on file level.</p>"},{"location":"user_stories/submission/submitter_guide/#studies-with-composition-of-technical-and-biological-replicates-in-a-time-series","title":"Studies with composition of technical and biological replicates in a time series","text":"<p>Table 3 - Different compositions between technical and biological replicates can be encoded on the research data file and sample level. Specific information like time series can be modeled by annotating the samples in name, description and attribute.</p>"},{"location":"user_stories/submission/submitter_guide/#study-with-research-data-processed-data-and-supplementary-data-files","title":"Study with research data, processed data and supplementary data files","text":"<p>Table 4 - Processed files, such as for alignment and variant calling can be added and additional phenotypic information can be submitted alongside the research data/processed files in form of supplementary files. For individuals, it can be indicated that further supplementary information exists that is accessible upon decryption of data.</p> <p>The shown examples show only the relevant parts of the metadata model in the long format, linking to samples, experiment, analysis via aliases has been inferred.</p>"},{"location":"user_stories/submission/submitter_guide/#3-metadata-validation","title":"3. Metadata validation","text":"<p>The GHGA Data Steward assists in case of any questions about the GHGA metadata schema. Once the metadata spreadsheet is finalized, it should be sent to the GHGA Helpdesk. </p> <p>To validate the submission, the GHGA Data Steward will use the GHGA Transpiler to generate a JSON of the submission. Should the linkage between entities contain structural or logical issues, they would be identified at this step. </p> <p>If a JSON can be generated from the submission, the GHGA Validator is used to validate the content of the submission. A report is generated that indicates errors issues with the submitted metadata, such as misalignments with controlled vocabularies or ontologies. This report is sent back by the Data Steward with recommendations on how to fix the issues. </p> <p></p> <p>Both Validator and Transpiler are publicly available and can be used by the submitter to validate the submission on their end.</p>"},{"location":"user_stories/submission/submitter_guide/#4-file-upload","title":"4. File upload","text":"<p>To submit the research data files to GHGA, the files have to be migrated to a GHGA Data Hub. The Data Stewards will assist in this process. Once the files are available at a Data Hub, the files are ingested in the GHGA Archive by the Data Steward using the GHGA DataSteward-Kit. </p>"},{"location":"user_stories/submission/submitter_guide/#5-publication-on-the-data-portal","title":"5. Publication on the Data Portal","text":"<p>Once the files are deposited and the metadata submitted to the GHGA Helpdesk, the submission is finalized but the data is not yet findable on the GHGA Data Portal. To make the metadata of the submission publicly findable and allow Data Access Requests to be started for the data, simply notify the GHGA Helpdesk. This will generate stable accessions that can be used to refer to the data deposition at GHGA.</p>"},{"location":"user_stories/submission/submitting_data/","title":"Submitting Data","text":"<p>A submission of data contains the three main steps, please follow the links for further information:</p> <p></p> <ol> <li>Filing a Pre-Submission Inquiry or contacting us via the 6251a85a-47d0-11ee-be56-0242ac120002:e4b25c750953eed77c6fbf81f82f6f83:&lt;__None__&gt;</li> <li>Agreement of a Data Processing Contract with GHGA Central</li> <li>Preparing the Data, including Metadata, for submission</li> </ol>"},{"location":"user_stories/submission/submitting_data/#note-on-submission-service","title":"Note on Submission Service","text":"<p>Limitations on External Submissions - November 2024</p> <p>GHGA has only recently launched the functionality of the GHGA Data Portal. Our ongoing efforts concentrate on improving the data upload processes and the overall user experience for external submissions. In general, data upload by external users is not yet possible as it includes manual steps. See also this section in our FAQ and the respective user story.</p>"}]}